<!doctype html>
<html data-n-head-ssr lang="ko" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22ko%22%7D%7D">
  <head>
    <title>MNIST로 보는 분류(Classification)</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="description" name="description" content="중앙대학교 Google DSC 블로그입니다."><meta data-n-head="ssr" name="format-detection" content="telephone=no"><meta data-n-head="ssr" data-hid="og:site_name" property="og:site_name" content="GDSC CAU"><meta data-n-head="ssr" data-hid="og:type" property="og:type" content="Blog"><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="t-type" name="twitter:card" content="summary_large_image"><meta data-n-head="ssr" data-hid="og-type" property="og:type" content="website"><meta data-n-head="ssr" data-hid="og:title" property="og:title" content="MNIST로 보는 분류(Classification)"><meta data-n-head="ssr" data-hid="og:description" property="og:description" content="MNIST dataset으로 보는 분류(Classification) 시스템을 구축하는 방법"><meta data-n-head="ssr" data-hid="og:image" property="og:image" content="https://raw.githubusercontent.com/GDSC-CAU/GDSC-CAU.github.io/main/static/opengraph_image.png"><meta data-n-head="ssr" data-hid="og:image:secure_url" property="og:image:secure_url" content="https://raw.githubusercontent.com/GDSC-CAU/GDSC-CAU.github.io/main/static/opengraph_image.png"><meta data-n-head="ssr" data-hid="og:image:alt" property="og:image:alt" content="MNIST로 보는 분류(Classification)"><meta data-n-head="ssr" data-hid="og:url" name="og:url" content="https://gdsc-cau.github.io/article/ai_ml-study-ch3"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="/favicon.png"><script data-n-head="ssr" data-hid="analytics" src="https://www.googletagmanager.com/gtag/js?id=G-78SE6PS7BD" defer></script><script data-n-head="ssr" data-hid="analytics-script" type="text/javascript">function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-78SE6PS7BD")</script><link rel="preload" href="/_nuxt/4f860e4.js" as="script"><link rel="preload" href="/_nuxt/05e7f4a.js" as="script"><link rel="preload" href="/_nuxt/f5f1fb1.js" as="script"><link rel="preload" href="/_nuxt/0145610.js" as="script"><link rel="preload" href="/_nuxt/2251c94.js" as="script"><style data-vue-ssr-id="54b08540:0 0d8b0c4d:0 06e030da:0 f0b2f15e:0 7b6ba9e4:0 bda82076:0 3f9ed770:0 6de78213:0 f9da4bca:0 00e17c61:0">/*! tailwindcss v3.2.3 | MIT License | https://tailwindcss.com*/*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e5e7eb}::after,::before{--tw-content:''}html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;-o-tab-size:4;tab-size:4;font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-feature-settings:normal}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit;border-collapse:collapse}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;font-weight:inherit;line-height:inherit;color:inherit;margin:0;padding:0}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}fieldset{margin:0;padding:0}legend{padding:0}menu,ol,ul{list-style:none;margin:0;padding:0}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{opacity:1;color:#9ca3af}input::placeholder,textarea::placeholder{opacity:1;color:#9ca3af}[role=button],button{cursor:pointer}:disabled{cursor:default}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}[hidden]{display:none}*,::after,::before{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-scroll-snap-strictness:proximity;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgb(59 130 246 / 0.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000}::backdrop{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-scroll-snap-strictness:proximity;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgb(59 130 246 / 0.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000}.prose{color:var(--tw-prose-body);max-width:65ch}.prose :where([class~=lead]):not(:where([class~=not-prose]*)){color:var(--tw-prose-lead);font-size:1.25em;line-height:1.6;margin-top:1.2em;margin-bottom:1.2em}.prose :where(a):not(:where([class~=not-prose]*)){color:var(--tw-prose-links);text-decoration:underline;font-weight:500}.prose :where(strong):not(:where([class~=not-prose]*)){color:var(--tw-prose-bold);font-weight:600}.prose :where(astrong):not(:where([class~=not-prose]*)){color:inherit}.prose :where(blockquotestrong):not(:where([class~=not-prose]*)){color:inherit}.prose :where(theadthstrong):not(:where([class~=not-prose]*)){color:inherit}.prose :where(ol):not(:where([class~=not-prose]*)){list-style-type:decimal;margin-top:1.25em;margin-bottom:1.25em;padding-left:1.625em}.prose :where(ol[type="A"]):not(:where([class~=not-prose]*)){list-style-type:upper-alpha}.prose :where(ol[type="a"]):not(:where([class~=not-prose]*)){list-style-type:lower-alpha}.prose :where(ol[type="A"s]):not(:where([class~=not-prose]*)){list-style-type:upper-alpha}.prose :where(ol[type="a"s]):not(:where([class~=not-prose]*)){list-style-type:lower-alpha}.prose :where(ol[type="I"]):not(:where([class~=not-prose]*)){list-style-type:upper-roman}.prose :where(ol[type="i"]):not(:where([class~=not-prose]*)){list-style-type:lower-roman}.prose :where(ol[type="I"s]):not(:where([class~=not-prose]*)){list-style-type:upper-roman}.prose :where(ol[type="i"s]):not(:where([class~=not-prose]*)){list-style-type:lower-roman}.prose :where(ol[type="1"]):not(:where([class~=not-prose]*)){list-style-type:decimal}.prose :where(ul):not(:where([class~=not-prose]*)){list-style-type:disc;margin-top:1.25em;margin-bottom:1.25em;padding-left:1.625em}.prose :where(ol>li):not(:where([class~=not-prose]*))::marker{font-weight:400;color:var(--tw-prose-counters)}.prose :where(ul>li):not(:where([class~=not-prose]*))::marker{color:var(--tw-prose-bullets)}.prose :where(hr):not(:where([class~=not-prose]*)){border-color:var(--tw-prose-hr);border-top-width:1px;margin-top:3em;margin-bottom:3em}.prose :where(blockquote):not(:where([class~=not-prose]*)){font-weight:500;font-style:italic;color:var(--tw-prose-quotes);border-left-width:.25rem;border-left-color:var(--tw-prose-quote-borders);quotes:"\201C""\201D""\2018""\2019";margin-top:1.6em;margin-bottom:1.6em;padding-left:1em}.prose :where(blockquotep:first-of-type):not(:where([class~=not-prose]*))::before{content:open-quote}.prose :where(blockquotep:last-of-type):not(:where([class~=not-prose]*))::after{content:close-quote}.prose :where(h1):not(:where([class~=not-prose]*)){color:var(--tw-prose-headings);font-weight:600;font-size:2.25em;margin-top:0;margin-bottom:.8888889em;line-height:1.1111111}.prose :where(h1strong):not(:where([class~=not-prose]*)){font-weight:900;color:inherit}.prose :where(h2):not(:where([class~=not-prose]*)){color:var(--tw-prose-headings);font-weight:600;font-size:1.5em;margin-top:2em;margin-bottom:1em;line-height:1.3333333}.prose :where(h2strong):not(:where([class~=not-prose]*)){font-weight:800;color:inherit}.prose :where(h3):not(:where([class~=not-prose]*)){color:var(--tw-prose-headings);font-weight:600;font-size:1.25em;margin-top:1.6em;margin-bottom:.6em;line-height:1.6}.prose :where(h3strong):not(:where([class~=not-prose]*)){font-weight:700;color:inherit}.prose :where(h4):not(:where([class~=not-prose]*)){color:var(--tw-prose-headings);font-weight:600;margin-top:1.5em;margin-bottom:.5em;line-height:1.5}.prose :where(h4strong):not(:where([class~=not-prose]*)){font-weight:700;color:inherit}.prose :where(img):not(:where([class~=not-prose]*)){margin-top:2em;margin-bottom:2em}.prose :where(figure>*):not(:where([class~=not-prose]*)){margin-top:0;margin-bottom:0}.prose :where(figcaption):not(:where([class~=not-prose]*)){color:var(--tw-prose-captions);font-size:.875em;line-height:1.4285714;margin-top:.8571429em}.prose :where(code):not(:where([class~=not-prose]*)){color:var(--tw-prose-code);font-weight:600;font-size:.875em}.prose :where(code):not(:where([class~=not-prose]*))::before{content:"`"}.prose :where(code):not(:where([class~=not-prose]*))::after{content:"`"}.prose :where(acode):not(:where([class~=not-prose]*)){color:inherit}.prose :where(h1code):not(:where([class~=not-prose]*)){color:inherit}.prose :where(h2code):not(:where([class~=not-prose]*)){color:inherit;font-size:.875em}.prose :where(h3code):not(:where([class~=not-prose]*)){color:inherit;font-size:.9em}.prose :where(h4code):not(:where([class~=not-prose]*)){color:inherit}.prose :where(blockquotecode):not(:where([class~=not-prose]*)){color:inherit}.prose :where(theadthcode):not(:where([class~=not-prose]*)){color:inherit}.prose :where(pre):not(:where([class~=not-prose]*)){color:var(--tw-prose-pre-code);background-color:var(--tw-prose-pre-bg);overflow-x:auto;font-weight:400;font-size:.875em;line-height:1.7142857;margin-top:1.7142857em;margin-bottom:1.7142857em;border-radius:.375rem;padding-top:.8571429em;padding-right:1.1428571em;padding-bottom:.8571429em;padding-left:1.1428571em}.prose :where(precode):not(:where([class~=not-prose]*)){background-color:transparent;border-width:0;border-radius:0;padding:0;font-weight:inherit;color:inherit;font-size:inherit;font-family:inherit;line-height:inherit}.prose :where(precode):not(:where([class~=not-prose]*))::before{content:none}.prose :where(precode):not(:where([class~=not-prose]*))::after{content:none}.prose :where(table):not(:where([class~=not-prose]*)){width:100%;table-layout:auto;text-align:left;margin-top:2em;margin-bottom:2em;font-size:.875em;line-height:1.7142857}.prose :where(thead):not(:where([class~=not-prose]*)){border-bottom-width:1px;border-bottom-color:var(--tw-prose-th-borders)}.prose :where(theadth):not(:where([class~=not-prose]*)){color:var(--tw-prose-headings);font-weight:600;vertical-align:bottom;padding-right:.5714286em;padding-bottom:.5714286em;padding-left:.5714286em}.prose :where(tbodytr):not(:where([class~=not-prose]*)){border-bottom-width:1px;border-bottom-color:var(--tw-prose-td-borders)}.prose :where(tbodytr:last-child):not(:where([class~=not-prose]*)){border-bottom-width:0}.prose :where(tbodytd):not(:where([class~=not-prose]*)){vertical-align:baseline}.prose :where(tfoot):not(:where([class~=not-prose]*)){border-top-width:1px;border-top-color:var(--tw-prose-th-borders)}.prose :where(tfoottd):not(:where([class~=not-prose]*)){vertical-align:top}.prose{--tw-prose-body:#374151;--tw-prose-headings:#111827;--tw-prose-lead:#4b5563;--tw-prose-links:#111827;--tw-prose-bold:#111827;--tw-prose-counters:#6b7280;--tw-prose-bullets:#d1d5db;--tw-prose-hr:#e5e7eb;--tw-prose-quotes:#111827;--tw-prose-quote-borders:#e5e7eb;--tw-prose-captions:#6b7280;--tw-prose-code:#111827;--tw-prose-pre-code:#e5e7eb;--tw-prose-pre-bg:#1f2937;--tw-prose-th-borders:#d1d5db;--tw-prose-td-borders:#e5e7eb;--tw-prose-invert-body:#d1d5db;--tw-prose-invert-headings:#fff;--tw-prose-invert-lead:#9ca3af;--tw-prose-invert-links:#fff;--tw-prose-invert-bold:#fff;--tw-prose-invert-counters:#9ca3af;--tw-prose-invert-bullets:#4b5563;--tw-prose-invert-hr:#374151;--tw-prose-invert-quotes:#f3f4f6;--tw-prose-invert-quote-borders:#374151;--tw-prose-invert-captions:#9ca3af;--tw-prose-invert-code:#fff;--tw-prose-invert-pre-code:#d1d5db;--tw-prose-invert-pre-bg:rgb(0 0 0 / 50%);--tw-prose-invert-th-borders:#4b5563;--tw-prose-invert-td-borders:#374151;font-size:1rem;line-height:1.75}.prose :where(p):not(:where([class~=not-prose]*)){margin-top:1.25em;margin-bottom:1.25em}.prose :where(video):not(:where([class~=not-prose]*)){margin-top:2em;margin-bottom:2em}.prose :where(figure):not(:where([class~=not-prose]*)){margin-top:2em;margin-bottom:2em}.prose :where(li):not(:where([class~=not-prose]*)){margin-top:.5em;margin-bottom:.5em}.prose :where(ol>li):not(:where([class~=not-prose]*)){padding-left:.375em}.prose :where(ul>li):not(:where([class~=not-prose]*)){padding-left:.375em}.prose :where(.prose>ul>lip):not(:where([class~=not-prose]*)){margin-top:.75em;margin-bottom:.75em}.prose :where(.prose>ul>li>:first-child):not(:where([class~=not-prose]*)){margin-top:1.25em}.prose :where(.prose>ul>li>:last-child):not(:where([class~=not-prose]*)){margin-bottom:1.25em}.prose :where(.prose>ol>li>:first-child):not(:where([class~=not-prose]*)){margin-top:1.25em}.prose :where(.prose>ol>li>:last-child):not(:where([class~=not-prose]*)){margin-bottom:1.25em}.prose :where(ulul,ulol,olul,olol):not(:where([class~=not-prose]*)){margin-top:.75em;margin-bottom:.75em}.prose :where(hr+*):not(:where([class~=not-prose]*)){margin-top:0}.prose :where(h2+*):not(:where([class~=not-prose]*)){margin-top:0}.prose :where(h3+*):not(:where([class~=not-prose]*)){margin-top:0}.prose :where(h4+*):not(:where([class~=not-prose]*)){margin-top:0}.prose :where(theadth:first-child):not(:where([class~=not-prose]*)){padding-left:0}.prose :where(theadth:last-child):not(:where([class~=not-prose]*)){padding-right:0}.prose :where(tbodytd,tfoottd):not(:where([class~=not-prose]*)){padding-top:.5714286em;padding-right:.5714286em;padding-bottom:.5714286em;padding-left:.5714286em}.prose :where(tbodytd:first-child,tfoottd:first-child):not(:where([class~=not-prose]*)){padding-left:0}.prose :where(tbodytd:last-child,tfoottd:last-child):not(:where([class~=not-prose]*)){padding-right:0}.prose :where(.prose>:first-child):not(:where([class~=not-prose]*)){margin-top:0}.prose :where(.prose>:last-child):not(:where([class~=not-prose]*)){margin-bottom:0}.prose :where(h5):not(:where([class~=not-prose]*)){font-weight:600}.static{position:static}.fixed{position:fixed}.absolute{position:absolute}.relative{position:relative}.inset-0{top:0;right:0;bottom:0;left:0}.top-0{top:0}.left-0{left:0}.right-0{right:0}.bottom-0{bottom:0}.z-40{z-index:40}.z-10{z-index:10}.z-30{z-index:30}.mx-auto{margin-left:auto;margin-right:auto}.my-4{margin-top:1rem;margin-bottom:1rem}.mb-3{margin-bottom:.75rem}.mr-0{margin-right:0}.mt-8{margin-top:2rem}.ml-1\.5{margin-left:.375rem}.ml-1{margin-left:.25rem}.mr-0\.5{margin-right:.125rem}.mt-4{margin-top:1rem}.mr-4{margin-right:1rem}.mt-6{margin-top:1.5rem}.ml-3{margin-left:.75rem}.mt-1{margin-top:.25rem}.mr-3{margin-right:.75rem}.mb-4{margin-bottom:1rem}.mr-9{margin-right:2.25rem}.mt-5{margin-top:1.25rem}.mb-1{margin-bottom:.25rem}.mt-14{margin-top:3.5rem}.mb-5{margin-bottom:1.25rem}.mb-6{margin-bottom:1.5rem}.mt-10{margin-top:2.5rem}.mb-2{margin-bottom:.5rem}.mb-16{margin-bottom:4rem}.block{display:block}.inline-block{display:inline-block}.flex{display:flex}.grid{display:grid}.hidden{display:none}.h-40{height:10rem}.h-2\/5{height:40%}.h-3\/5{height:60%}.h-6{height:1.5rem}.h-4{height:1rem}.h-full{height:100%}.h-5{height:1.25rem}.h-52{height:13rem}.h-56{height:14rem}.h-32{height:8rem}.h-72{height:18rem}.w-auto{width:auto}.w-full{width:100%}.w-64{width:16rem}.w-6{width:1.5rem}.w-5\/12{width:41.666667%}.w-40{width:10rem}.w-32{width:8rem}.max-w-6xl{max-width:72rem}.max-w-7xl{max-width:80rem}.max-w-5xl{max-width:64rem}.max-w-3xl{max-width:48rem}.flex-auto{flex:1 1 auto}.translate-x-0{--tw-translate-x:0px;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.-translate-x-full{--tw-translate-x:-100%;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.transform{transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.grid-cols-1{grid-template-columns:repeat(1,minmax(0,1fr))}.grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.flex-col{flex-direction:column}.content-center{align-content:center}.items-center{align-items:center}.justify-start{justify-content:flex-start}.justify-center{justify-content:center}.justify-between{justify-content:space-between}.gap-x-3{-moz-column-gap:.75rem;column-gap:.75rem}.gap-y-3{row-gap:.75rem}.gap-x-5{-moz-column-gap:1.25rem;column-gap:1.25rem}.gap-y-6{row-gap:1.5rem}.gap-y-9{row-gap:2.25rem}.space-y-2>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(.5rem * calc(1 - var(--tw-space-y-reverse)));margin-bottom:calc(.5rem * var(--tw-space-y-reverse))}.space-x-6>:not([hidden])~:not([hidden]){--tw-space-x-reverse:0;margin-right:calc(1.5rem * var(--tw-space-x-reverse));margin-left:calc(1.5rem * calc(1 - var(--tw-space-x-reverse)))}.space-x-2>:not([hidden])~:not([hidden]){--tw-space-x-reverse:0;margin-right:calc(.5rem * var(--tw-space-x-reverse));margin-left:calc(.5rem * calc(1 - var(--tw-space-x-reverse)))}.divide-y>:not([hidden])~:not([hidden]){--tw-divide-y-reverse:0;border-top-width:calc(.5px * calc(1 - var(--tw-divide-y-reverse)));border-bottom-width:calc(.5px * var(--tw-divide-y-reverse))}.overflow-auto{overflow:auto}.rounded-lg{border-radius:.5rem}.rounded-xl{border-radius:.75rem}.border{border-width:.5px}.border-b{border-bottom-width:.5px}.border-t{border-top-width:.5px}.border-gray-600{--tw-border-opacity:1;border-color:rgb(75 85 99 / var(--tw-border-opacity))}.border-gray-300{--tw-border-opacity:1;border-color:rgb(209 213 219 / var(--tw-border-opacity))}.border-gray-400{--tw-border-opacity:1;border-color:rgb(156 163 175 / var(--tw-border-opacity))}.bg-white{--tw-bg-opacity:1;background-color:rgb(255 255 255 / var(--tw-bg-opacity))}.bg-gray-50{--tw-bg-opacity:1;background-color:rgb(249 250 251 / var(--tw-bg-opacity))}.bg-black{--tw-bg-opacity:1;background-color:rgb(0 0 0 / var(--tw-bg-opacity))}.bg-opacity-75{--tw-bg-opacity:0.75}.p-5{padding:1.25rem}.p-3{padding:.75rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.px-2{padding-left:.5rem;padding-right:.5rem}.px-4{padding-left:1rem;padding-right:1rem}.py-4{padding-top:1rem;padding-bottom:1rem}.py-5{padding-top:1.25rem;padding-bottom:1.25rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-3{padding-top:.75rem;padding-bottom:.75rem}.px-5{padding-left:1.25rem;padding-right:1.25rem}.py-2\.5{padding-top:.625rem;padding-bottom:.625rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-0{padding-left:0;padding-right:0}.px-8{padding-left:2rem;padding-right:2rem}.py-8{padding-top:2rem;padding-bottom:2rem}.px-10{padding-left:2.5rem;padding-right:2.5rem}.pb-20{padding-bottom:5rem}.pt-11{padding-top:2.75rem}.pb-14{padding-bottom:3.5rem}.pb-9{padding-bottom:2.25rem}.pl-3{padding-left:.75rem}.pt-12{padding-top:3rem}.pb-8{padding-bottom:2rem}.pt-1{padding-top:.25rem}.pr-3\.5{padding-right:.875rem}.pr-3{padding-right:.75rem}.pt-28{padding-top:7rem}.pb-0{padding-bottom:0}.pb-6{padding-bottom:1.5rem}.pb-2\.5{padding-bottom:.625rem}.pb-2{padding-bottom:.5rem}.pl-8{padding-left:2rem}.pt-16{padding-top:4rem}.pl-0{padding-left:0}.pt-6{padding-top:1.5rem}.pb-12{padding-bottom:3rem}.pb-3{padding-bottom:.75rem}.pb-4{padding-bottom:1rem}.pr-4{padding-right:1rem}.pl-4{padding-left:1rem}.pr-6{padding-right:1.5rem}.pt-14{padding-top:3.5rem}.pt-10{padding-top:2.5rem}.pb-5{padding-bottom:1.25rem}.pt-0\.5{padding-top:.125rem}.pt-0{padding-top:0}.pb-16{padding-bottom:4rem}.pb-7{padding-bottom:1.75rem}.pb-1\.5{padding-bottom:.375rem}.pb-1{padding-bottom:.25rem}.pt-8{padding-top:2rem}.pb-10{padding-bottom:2.5rem}.text-left{text-align:left}.text-center{text-align:center}.text-right{text-align:right}.text-2xl{font-size:1.5rem;line-height:2rem}.text-sm{font-size:.875rem;line-height:1.25rem}.text-xs{font-size:.75rem;line-height:1rem}.text-base{font-size:1rem;line-height:1.5rem}.text-3xl{font-size:1.875rem;line-height:2.25rem}.text-5xl{font-size:3rem;line-height:1}.text-xl{font-size:1.25rem;line-height:1.75rem}.text-lg{font-size:1.125rem;line-height:1.75rem}.text-4xl{font-size:2.25rem;line-height:2.5rem}.font-light{font-weight:300}.font-medium{font-weight:500}.font-normal{font-weight:400}.font-semibold{font-weight:600}.leading-snug{line-height:1.375}.text-gray-800{--tw-text-opacity:1;color:rgb(31 41 55 / var(--tw-text-opacity))}.text-gray-600{--tw-text-opacity:1;color:rgb(75 85 99 / var(--tw-text-opacity))}.text-blue-500{--tw-text-opacity:1;color:rgb(59 130 246 / var(--tw-text-opacity))}.text-gray-300{--tw-text-opacity:1;color:rgb(209 213 219 / var(--tw-text-opacity))}.text-gray-500{--tw-text-opacity:1;color:rgb(107 114 128 / var(--tw-text-opacity))}.text-gray-700{--tw-text-opacity:1;color:rgb(55 65 81 / var(--tw-text-opacity))}.text-gray-400{--tw-text-opacity:1;color:rgb(156 163 175 / var(--tw-text-opacity))}.underline{text-decoration-line:underline}.opacity-0{opacity:0}.opacity-100{opacity:1}.opacity-50{opacity:.5}.shadow-sm{--tw-shadow:0 1px 2px 0 rgb(0 0 0 / 0.05);--tw-shadow-colored:0 1px 2px 0 var(--tw-shadow-color);box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.outline{outline-style:solid}.invert{--tw-invert:invert(100%);filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.sepia{--tw-sepia:sepia(100%);filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.filter{filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.transition{transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:150ms}.transition-opacity{transition-property:opacity;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:150ms}.transition-all{transition-property:all;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:150ms}.duration-300{transition-duration:.3s}.duration-200{transition-duration:.2s}.ease-out{transition-timing-function:cubic-bezier(0,0,.2,1)}.ease-in-out{transition-timing-function:cubic-bezier(.4,0,.2,1)}.hover\:border-gray-400:hover{--tw-border-opacity:1;border-color:rgb(156 163 175 / var(--tw-border-opacity))}.hover\:bg-white:hover{--tw-bg-opacity:1;background-color:rgb(255 255 255 / var(--tw-bg-opacity))}.hover\:text-gray-800:hover{--tw-text-opacity:1;color:rgb(31 41 55 / var(--tw-text-opacity))}.hover\:underline:hover{text-decoration-line:underline}.hover\:duration-300:hover{transition-duration:.3s}.group:hover .group-hover\:bg-opacity-50{--tw-bg-opacity:0.5}.group:hover .group-hover\:text-gray-700{--tw-text-opacity:1;color:rgb(55 65 81 / var(--tw-text-opacity))}.group:hover .group-hover\:underline{text-decoration-line:underline}@media (min-width:640px){.sm\:h-44{height:11rem}.sm\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}}@media (min-width:768px){.md\:col-span-3{grid-column:span 3/span 3}.md\:mr-3{margin-right:.75rem}.md\:mt-0{margin-top:0}.md\:ml-0{margin-left:0}.md\:mr-0{margin-right:0}.md\:mb-6{margin-bottom:1.5rem}.md\:mb-5{margin-bottom:1.25rem}.md\:mt-8{margin-top:2rem}.md\:mb-1\.5{margin-bottom:.375rem}.md\:mb-1{margin-bottom:.25rem}.md\:mt-24{margin-top:6rem}.md\:mb-8{margin-bottom:2rem}.md\:mb-10{margin-bottom:2.5rem}.md\:mt-20{margin-top:5rem}.md\:block{display:block}.md\:inline{display:inline}.md\:flex{display:flex}.md\:hidden{display:none}.md\:h-auto{height:auto}.md\:h-52{height:13rem}.md\:h-40{height:10rem}.md\:h-96{height:24rem}.md\:w-52{width:13rem}.md\:w-40{width:10rem}.md\:grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}.md\:grid-cols-5{grid-template-columns:repeat(5,minmax(0,1fr))}.md\:flex-row{flex-direction:row}.md\:items-center{align-items:center}.md\:justify-between{justify-content:space-between}.md\:gap-y-0{row-gap:0}.md\:gap-x-5{-moz-column-gap:1.25rem;column-gap:1.25rem}.md\:space-y-0>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(0px * calc(1 - var(--tw-space-y-reverse)));margin-bottom:calc(0px * var(--tw-space-y-reverse))}.md\:rounded-xl{border-radius:.75rem}.md\:border-b{border-bottom-width:.5px}.md\:border-gray-300{--tw-border-opacity:1;border-color:rgb(209 213 219 / var(--tw-border-opacity))}.md\:bg-gray-50{--tw-bg-opacity:1;background-color:rgb(249 250 251 / var(--tw-bg-opacity))}.md\:px-5{padding-left:1.25rem;padding-right:1.25rem}.md\:py-5{padding-top:1.25rem;padding-bottom:1.25rem}.md\:px-8{padding-left:2rem;padding-right:2rem}.md\:py-6{padding-top:1.5rem;padding-bottom:1.5rem}.md\:py-3\.5{padding-top:.875rem;padding-bottom:.875rem}.md\:py-3{padding-top:.75rem;padding-bottom:.75rem}.md\:px-6{padding-left:1.5rem;padding-right:1.5rem}.md\:py-8{padding-top:2rem;padding-bottom:2rem}.md\:px-0{padding-left:0;padding-right:0}.md\:px-20{padding-left:5rem;padding-right:5rem}.md\:pb-32{padding-bottom:8rem}.md\:pt-11{padding-top:2.75rem}.md\:pb-24{padding-bottom:6rem}.md\:pt-0{padding-top:0}.md\:pr-6{padding-right:1.5rem}.md\:pt-52{padding-top:13rem}.md\:pb-10{padding-bottom:2.5rem}.md\:pt-24{padding-top:6rem}.md\:pt-16{padding-top:4rem}.md\:pl-12{padding-left:3rem}.md\:pb-16{padding-bottom:4rem}.md\:pb-6{padding-bottom:1.5rem}.md\:pt-36{padding-top:9rem}.md\:pb-28{padding-bottom:7rem}.md\:pt-44{padding-top:11rem}.md\:pt-20{padding-top:5rem}.md\:pb-20{padding-bottom:5rem}.md\:pb-3\.5{padding-bottom:.875rem}.md\:pb-3{padding-bottom:.75rem}.md\:pb-4{padding-bottom:1rem}.md\:pt-40{padding-top:10rem}.md\:pb-1\.5{padding-bottom:.375rem}.md\:pb-1{padding-bottom:.25rem}.md\:pb-12{padding-bottom:3rem}.md\:pb-14{padding-bottom:3.5rem}.md\:text-left{text-align:left}.md\:text-right{text-align:right}.md\:text-sm{font-size:.875rem;line-height:1.25rem}.md\:text-7xl{font-size:4.5rem;line-height:1}.md\:text-3xl{font-size:1.875rem;line-height:2.25rem}.md\:text-lg{font-size:1.125rem;line-height:1.75rem}.md\:text-4xl{font-size:2.25rem;line-height:2.5rem}.md\:text-xl{font-size:1.25rem;line-height:1.75rem}.md\:text-base{font-size:1rem;line-height:1.5rem}.md\:text-5xl{font-size:3rem;line-height:1}.md\:text-2xl{font-size:1.5rem;line-height:2rem}.md\:leading-normal{line-height:1.5}.md\:shadow{--tw-shadow:0 1px 3px 0 rgb(0 0 0 / 0.1),0 1px 2px -1px rgb(0 0 0 / 0.1);--tw-shadow-colored:0 1px 3px 0 var(--tw-shadow-color),0 1px 2px -1px var(--tw-shadow-color);box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}}code[class*=language-],pre[class*=language-]{color:#000;background:0 0;text-shadow:0 1px #fff;font-family:Consolas,Monaco,"Andale Mono","Ubuntu Mono",monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;hyphens:none}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{text-shadow:none;background:#b3d4fc}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{text-shadow:none;background:#b3d4fc}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#b3d4fc}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{color:#9a6e3a;background:hsla(0,0%,100%,.5)}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.nuxt-progress{position:fixed;top:0;left:0;right:0;height:2px;width:0;opacity:1;transition:width .1s,opacity .4s;background-color:#000;z-index:999999}.nuxt-progress.nuxt-progress-notransition{transition:none}.nuxt-progress-failed{background-color:red}*{font-family:Inter,"Spoqa Han Sans Neo",Poppins,sans-serif}@font-face{font-family:"Spoqa Han Sans Neo";font-weight:700;src:local("Spoqa Han Sans Neo Bold"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Bold.woff2) format("woff2"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Bold.woff) format("woff"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Bold.ttf) format("truetype");unicode-range:u+ac00-d7af}@font-face{font-family:"Spoqa Han Sans Neo";font-weight:500;src:local("Spoqa Han Sans Neo Medium"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Medium.woff2) format("woff2"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Medium.woff) format("woff"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Medium.ttf) format("truetype");unicode-range:u+ac00-d7af}@font-face{font-family:"Spoqa Han Sans Neo";font-weight:400;src:local("Spoqa Han Sans Neo Regular"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Regular.woff2) format("woff2"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Regular.woff) format("woff"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Regular.ttf) format("truetype");unicode-range:u+ac00-d7af}@font-face{font-family:"Spoqa Han Sans Neo";font-weight:300;src:local("Spoqa Han Sans Neo Light"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Light.woff2) format("woff2"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Light.woff) format("woff"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Light.ttf) format("truetype");unicode-range:u+ac00-d7af}@font-face{font-family:"Spoqa Han Sans Neo";font-weight:100;src:local("Spoqa Han Sans Neo Thin"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Thin.woff2) format("woff2"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Thin.woff) format("woff"),url(https://cdn.jsdelivr.net/gh/spoqa/spoqa-han-sans@latest/Subset/SpoqaHanSansNeo/SpoqaHanSansNeo-Thin.ttf) format("truetype");unicode-range:u+ac00-d7af}@font-face{font-family:Inter;font-style:normal;font-weight:100;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:100;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:100;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:100;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:100;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:100;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:100;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Inter;font-style:normal;font-weight:200;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:200;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:200;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:200;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:200;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:200;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:200;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Inter;font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Inter;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Inter;font-style:normal;font-weight:500;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:500;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:500;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:500;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:500;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:500;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:500;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Inter;font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:600;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Inter;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Inter;font-style:normal;font-weight:800;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:800;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:800;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:800;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:800;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:800;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:800;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Inter;font-style:normal;font-weight:900;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-family:Inter;font-style:normal;font-weight:900;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-family:Inter;font-style:normal;font-weight:900;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+1f??}@font-face{font-family:Inter;font-style:normal;font-weight:900;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0370-03ff}@font-face{font-family:Inter;font-style:normal;font-weight:900;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-family:Inter;font-style:normal;font-weight:900;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-family:Inter;font-style:normal;font-weight:900;src:url(https://fonts.gstatic.com/s/inter/v3/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-family:Poppins;font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiGyp8kv8JHgFVrLPTucXtAOvWDSHFF.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiGyp8kv8JHgFVrLPTufntAOvWDSHFF.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:100;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiGyp8kv8JHgFVrLPTucHtAOvWDSA.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLFj_Z11lFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLFj_Z1JlFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLFj_Z1xlFd2JQEk.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDz8Z11lFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDz8Z1JlFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDz8Z1xlFd2JQEk.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJbecnFHGPezSQ.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJnecnFHGPezSQ.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJfecnFHGPc.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLGT9Z11lFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLGT9Z1JlFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLGT9Z1xlFd2JQEk.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z11lFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z1JlFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z1xlFd2JQEk.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z11lFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z1JlFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z1xlFd2JQEk.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDD4Z11lFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDD4Z1JlFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:800;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDD4Z1xlFd2JQEk.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLBT5Z11lFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLBT5Z1JlFd2JQEl8qw.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}@font-face{font-family:Poppins;font-style:normal;font-weight:900;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLBT5Z1xlFd2JQEk.woff2) format("woff2");unicode-range:u+0041-005a,u+0061-007a}.poppins{font-family:Poppins,"Spoqa Han Sans",Inter}.absol{position:relative}.fixed{position:fixed}.octcat-color[data-v-2a77734c]{filter:invert(66%) sepia(11%) saturate(293%) hue-rotate(179deg) brightness(96%) contrast(89%)}.octcat-color[data-v-2a77734c]:hover{filter:invert(31%) sepia(9%) saturate(984%) hue-rotate(174deg) brightness(97%) contrast(87%);transition:.2s}.octcat-color[data-v-696fe586]{filter:invert(66%) sepia(11%) saturate(293%) hue-rotate(179deg) brightness(96%) contrast(89%)}.octcat-color[data-v-696fe586]:hover{filter:invert(31%) sepia(9%) saturate(984%) hue-rotate(174deg) brightness(97%) contrast(87%);transition:.2s}.octcat-color[data-v-209c04fb]{filter:invert(66%) sepia(11%) saturate(293%) hue-rotate(179deg) brightness(96%) contrast(89%)}.octcat-color[data-v-064e0d9e]{filter:invert(66%) sepia(11%) saturate(293%) hue-rotate(179deg) brightness(96%) contrast(89%)}.octcat-color[data-v-064e0d9e]:hover{filter:invert(31%) sepia(9%) saturate(984%) hue-rotate(174deg) brightness(97%) contrast(87%);transition:.2s}img{margin-left:auto;margin-right:auto}.custom-text{word-break:keep-all}.box{width:150px;height:150px;border-radius:70%;overflow:hidden}.profile{width:100%;height:100%;-o-object-fit:cover;object-fit:cover}.custom-text[data-v-d6278ec4]{word-break:keep-all}</style><link rel="preload" href="/_nuxt/static/1668135659/articles/ai_ml-study-ch3/state.js" as="script"><link rel="preload" href="/_nuxt/static/1668135659/articles/ai_ml-study-ch3/payload.js" as="script"><link rel="preload" href="/_nuxt/static/1668135659/manifest.js" as="script">
  </head>
  <body>
    <div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div class="absol"><div class="w-full border-b md:border-b border-gray-300 bg-white z-40 fixed px-0 md:px-5" data-v-1a4f42dc><div class="max-w-7xl mx-auto flex items-center justify-between px-4" data-v-1a4f42dc><div class="ml-1.5 md:ml-0 flex w-full py-4 md:py-5" data-v-1a4f42dc><ul class="flex space-x-6 items-center" data-v-1a4f42dc><li data-v-1a4f42dc><a href="/" class="nuxt-link-active" data-v-1a4f42dc><svg viewBox="0 0 2950 500" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" class="w-auto md:block h-6" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2" data-v-6b5b6345 data-v-1a4f42dc><g transform="matrix(1.04366,0,0,1.04366,3.30222,-10.9151)" data-v-6b5b6345><g transform="matrix(3.17657,0,0,3.17657,218.269,65.6614)" data-v-6b5b6345><path d="M0,56.813C0.104,56.853 0.22,56.845 0.317,56.791L36.566,36.501C45.134,31.707 48.229,20.712 43.48,11.947C38.73,3.181 27.937,-0.04 19.369,4.756L-42.813,39.56C-43.096,39.718 -43.065,40.144 -42.762,40.261L0,56.813Z" style="fill:#e84435;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,302.093,177.885)" data-v-6b5b6345><path d="M0,76.736C6.129,76.881 12.145,73.776 15.529,68.051C20.574,59.516 17.856,48.384 9.46,43.191L-52.188,5.052C-60.585,-0.145 -71.48,2.567 -76.525,11.102C-81.57,19.638 -78.853,30.768 -70.457,35.963L-8.808,74.101C-6.044,75.812 -3.008,76.665 0,76.736" style="fill:#2376e5;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,498.874,252.966)" data-v-6b5b6345><path d="M0,54.559C3.009,54.63 6.07,53.92 8.892,52.341L71.083,17.532C71.364,17.374 71.336,16.952 71.035,16.832L28.826,-0.029C28.722,-0.071 28.604,-0.064 28.506,-0.008L-8.306,20.595C-16.873,25.39 -19.969,36.384 -15.22,45.15C-12.034,51.03 -6.129,54.414 0,54.559" style="fill:#f6ba17;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,698.58,70.6884)" data-v-6b5b6345><path d="M0,76.734C6.13,76.879 12.145,73.776 15.529,68.049C20.574,59.514 17.856,48.384 9.46,43.189L-52.188,5.049C-60.584,-0.145 -71.479,2.563 -76.524,11.099C-81.569,19.634 -78.853,30.764 -70.456,35.96L-8.808,74.099C-6.044,75.809 -3.008,76.663 0,76.734" style="fill:#089d57;fill-rule:nonzero" data-v-6b5b6345></path></g></g> <g transform="matrix(4.0904,0,0,4.0904,-2519.11,-940.815)" data-v-6b5b6345><path d="M888.004,315.948C878.112,315.948 869.837,312.62 863.18,305.963C856.586,299.306 853.288,291 853.288,281.046C853.288,271.092 856.586,262.817 863.18,256.222C869.775,249.503 878.049,246.144 888.004,246.144C898.082,246.144 906.264,249.783 912.547,257.062L906.388,263.035C901.597,257.249 895.469,254.356 888.004,254.356C880.6,254.356 874.41,256.845 869.433,261.822C864.518,266.737 862.06,273.145 862.06,281.046C862.06,288.947 864.518,295.355 869.433,300.27C874.41,305.247 880.6,307.736 888.004,307.736C895.78,307.736 902.531,304.47 908.254,297.937L914.507,304.003C911.334,307.798 907.446,310.738 902.842,312.822C898.238,314.906 893.292,315.948 888.004,315.948Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M922.159,247.637L930.745,247.637L930.745,268.728L930.372,275.073L930.745,275.073C932.051,272.834 934.058,270.967 936.764,269.474C939.47,267.981 942.286,267.234 945.21,267.234C950.809,267.234 955.117,268.836 958.135,272.04C961.152,275.244 962.661,279.802 962.661,285.712L962.661,314.455L954.075,314.455L954.075,287.392C954.075,279.18 950.436,275.073 943.157,275.073C939.673,275.073 936.733,276.52 934.338,279.413C931.942,282.306 930.745,285.681 930.745,289.538L930.745,314.455L922.159,314.455L922.159,247.637Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1012.87,314.455L1004.65,314.455L1004.65,308.109L1004.28,308.109C1002.98,310.349 1000.97,312.215 998.263,313.708C995.556,315.201 992.741,315.948 989.817,315.948C984.218,315.948 979.91,314.346 976.892,311.142C973.875,307.938 972.366,303.381 972.366,297.47L972.366,268.728L980.952,268.728L980.952,296.911C981.138,304.376 984.902,308.109 992.243,308.109C995.665,308.109 998.527,306.725 1000.83,303.956C1003.13,301.188 1004.28,297.875 1004.28,294.018L1004.28,268.728L1012.87,268.728L1012.87,314.455Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1023.32,268.728L1031.53,268.728L1031.53,275.073L1031.9,275.073C1033.21,272.834 1035.22,270.967 1037.92,269.474C1040.63,267.981 1043.45,267.234 1046.37,267.234C1051.97,267.234 1056.28,268.836 1059.3,272.04C1062.31,275.244 1063.82,279.802 1063.82,285.712L1063.82,314.455L1055.24,314.455L1055.24,286.272C1055.05,278.806 1051.29,275.073 1043.94,275.073C1040.52,275.073 1037.66,276.458 1035.36,279.226C1033.06,281.995 1031.9,285.308 1031.9,289.165L1031.9,314.455L1023.32,314.455L1023.32,268.728Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1093.96,308.109C1098.19,308.109 1101.65,306.585 1104.32,303.536C1107.12,300.488 1108.52,296.506 1108.52,291.591C1108.52,286.801 1107.12,282.85 1104.32,279.739C1101.59,276.629 1098.13,275.073 1093.96,275.073C1089.86,275.073 1086.4,276.629 1083.61,279.739C1080.81,282.85 1079.4,286.801 1079.4,291.591C1079.4,296.444 1080.81,300.395 1083.61,303.443C1086.4,306.554 1089.86,308.109 1093.96,308.109ZM1093.68,336.105C1091.13,336.105 1088.74,335.779 1086.5,335.126C1084.26,334.472 1082.22,333.555 1080.38,332.373C1078.55,331.191 1076.98,329.791 1075.67,328.173C1074.37,326.556 1073.37,324.751 1072.69,322.761L1080.81,319.401C1081.74,322.076 1083.36,324.223 1085.66,325.84C1087.96,327.458 1090.63,328.266 1093.68,328.266C1098.35,328.266 1101.99,326.867 1104.6,324.067C1107.21,321.267 1108.52,317.41 1108.52,312.495L1108.52,308.109L1108.15,308.109C1106.53,310.535 1104.34,312.449 1101.57,313.848C1098.8,315.248 1095.8,315.948 1092.56,315.948C1086.59,315.948 1081.46,313.615 1077.17,308.949C1072.93,304.158 1070.82,298.373 1070.82,291.591C1070.82,284.81 1072.93,279.055 1077.17,274.327C1081.46,269.599 1086.59,267.234 1092.56,267.234C1095.8,267.234 1098.8,267.934 1101.57,269.334C1104.34,270.734 1106.53,272.647 1108.15,275.073L1108.52,275.073L1108.52,268.728L1116.73,268.728L1116.73,312.495C1116.73,319.836 1114.65,325.591 1110.48,329.76C1106.25,333.99 1100.65,336.105 1093.68,336.105Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <rect x="1127.19" y="281.979" width="29.863" height="7.092" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></rect> <path d="M1193.26,258.182L1182.34,288.325L1204.55,288.325L1193.63,258.182L1193.26,258.182ZM1172.91,314.455L1163.39,314.455L1188.59,247.637L1198.3,247.637L1223.49,314.455L1213.98,314.455L1207.54,296.351L1179.45,296.351L1172.91,314.455Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1229.84,268.728L1238.05,268.728L1238.05,275.073L1238.42,275.073C1239.73,272.834 1241.74,270.967 1244.44,269.474C1247.15,267.981 1249.97,267.234 1252.89,267.234C1258.49,267.234 1262.8,268.836 1265.82,272.04C1268.83,275.244 1270.34,279.802 1270.34,285.712L1270.34,314.455L1261.76,314.455L1261.76,286.272C1261.57,278.806 1257.8,275.073 1250.46,275.073C1247.04,275.073 1244.18,276.458 1241.88,279.226C1239.58,281.995 1238.42,285.308 1238.42,289.165L1238.42,314.455L1229.84,314.455L1229.84,268.728Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1300.48,308.109C1304.71,308.109 1308.17,306.585 1310.84,303.536C1313.64,300.488 1315.04,296.506 1315.04,291.591C1315.04,286.801 1313.64,282.85 1310.84,279.739C1308.11,276.629 1304.65,275.073 1300.48,275.073C1296.38,275.073 1292.92,276.629 1290.12,279.739C1287.33,282.85 1285.92,286.801 1285.92,291.591C1285.92,296.444 1287.33,300.395 1290.12,303.443C1292.92,306.554 1296.38,308.109 1300.48,308.109ZM1300.2,336.105C1297.65,336.105 1295.26,335.779 1293.02,335.126C1290.78,334.472 1288.74,333.555 1286.9,332.373C1285.07,331.191 1283.5,329.791 1282.19,328.173C1280.89,326.556 1279.89,324.751 1279.21,322.761L1287.33,319.401C1288.26,322.076 1289.88,324.223 1292.18,325.84C1294.48,327.458 1297.15,328.266 1300.2,328.266C1304.87,328.266 1308.51,326.867 1311.12,324.067C1313.74,321.267 1315.04,317.41 1315.04,312.495L1315.04,308.109L1314.67,308.109C1313.05,310.535 1310.86,312.449 1308.09,313.848C1305.32,315.248 1302.32,315.948 1299.08,315.948C1293.11,315.948 1287.98,313.615 1283.69,308.949C1279.45,304.158 1277.34,298.373 1277.34,291.591C1277.34,284.81 1279.45,279.055 1283.69,274.327C1287.98,269.599 1293.11,267.234 1299.08,267.234C1302.32,267.234 1305.32,267.934 1308.09,269.334C1310.86,270.734 1313.05,272.647 1314.67,275.073L1315.04,275.073L1315.04,268.728L1323.25,268.728L1323.25,312.495C1323.25,319.836 1321.17,325.591 1317,329.76C1312.77,333.99 1307.17,336.105 1300.2,336.105Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path></g></svg></a></li> <li class="hidden md:block text-gray-500 pl-3 hover:text-gray-800 transition hover:duration-300 font-light" data-v-1a4f42dc><a href="/about" class="poppins" data-v-1a4f42dc>About</a></li> <li class="hidden md:block poppins text-gray-500 hover:text-gray-800 transition hover:duration-300 font-light" data-v-1a4f42dc><a href="/articles" class="poppins nuxt-link-active" data-v-1a4f42dc>Articles</a></li> <li class="hidden md:block poppins text-gray-500 hover:text-gray-800 transition hover:duration-300 font-light" data-v-1a4f42dc><a href="/categories" class="poppins" data-v-1a4f42dc>Categories</a></li> <li class="hidden md:block poppins text-gray-500 hover:text-gray-800 transition hover:duration-300 font-light" data-v-1a4f42dc><a href="/members" class="poppins" data-v-1a4f42dc>Members</a></li> <li class="hidden md:block poppins text-gray-500 hover:text-gray-800 transition hover:duration-300 font-light" data-v-1a4f42dc><a href="/projects" class="poppins" data-v-1a4f42dc>Projects</a></li></ul></div> <div class="md:hidden flex content-center" data-v-1a4f42dc><button data-v-1a4f42dc><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" class="fill-current text-gray-300 w-auto md:block h-5 octcat-color mr-0.5" data-v-2a77734c data-v-1a4f42dc><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7" data-v-2a77734c></path></svg></button></div> <div class="flex hidden md:block py-5" data-v-1a4f42dc><ul class="flex space-x-2 text-base items-center" data-v-1a4f42dc><li data-v-1a4f42dc><div class="hidden md:block group" data-v-1a4f42dc><a href="https://github.com/GDSC-CAU" target="blank" data-v-1a4f42dc><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current text-gray-300 w-auto md:block h-6 octcat-color" data-v-696fe586 data-v-1a4f42dc><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" data-v-696fe586></path></svg></a></div></li></ul></div> <div class="z-10 fixed inset-0 transition-opacity" style="display:none" data-v-1a4f42dc data-v-1a4f42dc><div tabindex="0" class="absolute inset-0 bg-black opacity-50" data-v-1a4f42dc></div></div> <aside class="p-5 transform top-0 left-0 w-64 bg-white fixed h-full overflow-auto ease-in-out transition-all duration-300 z-30 -translate-x-full" data-v-1a4f42dc><div class="close" data-v-1a4f42dc><button class="absolute top-0 right-0 mt-4 mr-4" data-v-1a4f42dc><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" class="fill-current text-gray-300 w-auto md:block h-6 octcat-color" data-v-209c04fb data-v-1a4f42dc><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" data-v-209c04fb></path></svg></button></div> <div class="flex w-full pt-12 pb-8 items-center justify-center border-b" data-v-1a4f42dc><svg viewBox="0 0 2950 500" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" class="w-auto md:block h-6" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2" data-v-6b5b6345 data-v-1a4f42dc><g transform="matrix(1.04366,0,0,1.04366,3.30222,-10.9151)" data-v-6b5b6345><g transform="matrix(3.17657,0,0,3.17657,218.269,65.6614)" data-v-6b5b6345><path d="M0,56.813C0.104,56.853 0.22,56.845 0.317,56.791L36.566,36.501C45.134,31.707 48.229,20.712 43.48,11.947C38.73,3.181 27.937,-0.04 19.369,4.756L-42.813,39.56C-43.096,39.718 -43.065,40.144 -42.762,40.261L0,56.813Z" style="fill:#e84435;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,302.093,177.885)" data-v-6b5b6345><path d="M0,76.736C6.129,76.881 12.145,73.776 15.529,68.051C20.574,59.516 17.856,48.384 9.46,43.191L-52.188,5.052C-60.585,-0.145 -71.48,2.567 -76.525,11.102C-81.57,19.638 -78.853,30.768 -70.457,35.963L-8.808,74.101C-6.044,75.812 -3.008,76.665 0,76.736" style="fill:#2376e5;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,498.874,252.966)" data-v-6b5b6345><path d="M0,54.559C3.009,54.63 6.07,53.92 8.892,52.341L71.083,17.532C71.364,17.374 71.336,16.952 71.035,16.832L28.826,-0.029C28.722,-0.071 28.604,-0.064 28.506,-0.008L-8.306,20.595C-16.873,25.39 -19.969,36.384 -15.22,45.15C-12.034,51.03 -6.129,54.414 0,54.559" style="fill:#f6ba17;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,698.58,70.6884)" data-v-6b5b6345><path d="M0,76.734C6.13,76.879 12.145,73.776 15.529,68.049C20.574,59.514 17.856,48.384 9.46,43.189L-52.188,5.049C-60.584,-0.145 -71.479,2.563 -76.524,11.099C-81.569,19.634 -78.853,30.764 -70.456,35.96L-8.808,74.099C-6.044,75.809 -3.008,76.663 0,76.734" style="fill:#089d57;fill-rule:nonzero" data-v-6b5b6345></path></g></g> <g transform="matrix(4.0904,0,0,4.0904,-2519.11,-940.815)" data-v-6b5b6345><path d="M888.004,315.948C878.112,315.948 869.837,312.62 863.18,305.963C856.586,299.306 853.288,291 853.288,281.046C853.288,271.092 856.586,262.817 863.18,256.222C869.775,249.503 878.049,246.144 888.004,246.144C898.082,246.144 906.264,249.783 912.547,257.062L906.388,263.035C901.597,257.249 895.469,254.356 888.004,254.356C880.6,254.356 874.41,256.845 869.433,261.822C864.518,266.737 862.06,273.145 862.06,281.046C862.06,288.947 864.518,295.355 869.433,300.27C874.41,305.247 880.6,307.736 888.004,307.736C895.78,307.736 902.531,304.47 908.254,297.937L914.507,304.003C911.334,307.798 907.446,310.738 902.842,312.822C898.238,314.906 893.292,315.948 888.004,315.948Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M922.159,247.637L930.745,247.637L930.745,268.728L930.372,275.073L930.745,275.073C932.051,272.834 934.058,270.967 936.764,269.474C939.47,267.981 942.286,267.234 945.21,267.234C950.809,267.234 955.117,268.836 958.135,272.04C961.152,275.244 962.661,279.802 962.661,285.712L962.661,314.455L954.075,314.455L954.075,287.392C954.075,279.18 950.436,275.073 943.157,275.073C939.673,275.073 936.733,276.52 934.338,279.413C931.942,282.306 930.745,285.681 930.745,289.538L930.745,314.455L922.159,314.455L922.159,247.637Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1012.87,314.455L1004.65,314.455L1004.65,308.109L1004.28,308.109C1002.98,310.349 1000.97,312.215 998.263,313.708C995.556,315.201 992.741,315.948 989.817,315.948C984.218,315.948 979.91,314.346 976.892,311.142C973.875,307.938 972.366,303.381 972.366,297.47L972.366,268.728L980.952,268.728L980.952,296.911C981.138,304.376 984.902,308.109 992.243,308.109C995.665,308.109 998.527,306.725 1000.83,303.956C1003.13,301.188 1004.28,297.875 1004.28,294.018L1004.28,268.728L1012.87,268.728L1012.87,314.455Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1023.32,268.728L1031.53,268.728L1031.53,275.073L1031.9,275.073C1033.21,272.834 1035.22,270.967 1037.92,269.474C1040.63,267.981 1043.45,267.234 1046.37,267.234C1051.97,267.234 1056.28,268.836 1059.3,272.04C1062.31,275.244 1063.82,279.802 1063.82,285.712L1063.82,314.455L1055.24,314.455L1055.24,286.272C1055.05,278.806 1051.29,275.073 1043.94,275.073C1040.52,275.073 1037.66,276.458 1035.36,279.226C1033.06,281.995 1031.9,285.308 1031.9,289.165L1031.9,314.455L1023.32,314.455L1023.32,268.728Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1093.96,308.109C1098.19,308.109 1101.65,306.585 1104.32,303.536C1107.12,300.488 1108.52,296.506 1108.52,291.591C1108.52,286.801 1107.12,282.85 1104.32,279.739C1101.59,276.629 1098.13,275.073 1093.96,275.073C1089.86,275.073 1086.4,276.629 1083.61,279.739C1080.81,282.85 1079.4,286.801 1079.4,291.591C1079.4,296.444 1080.81,300.395 1083.61,303.443C1086.4,306.554 1089.86,308.109 1093.96,308.109ZM1093.68,336.105C1091.13,336.105 1088.74,335.779 1086.5,335.126C1084.26,334.472 1082.22,333.555 1080.38,332.373C1078.55,331.191 1076.98,329.791 1075.67,328.173C1074.37,326.556 1073.37,324.751 1072.69,322.761L1080.81,319.401C1081.74,322.076 1083.36,324.223 1085.66,325.84C1087.96,327.458 1090.63,328.266 1093.68,328.266C1098.35,328.266 1101.99,326.867 1104.6,324.067C1107.21,321.267 1108.52,317.41 1108.52,312.495L1108.52,308.109L1108.15,308.109C1106.53,310.535 1104.34,312.449 1101.57,313.848C1098.8,315.248 1095.8,315.948 1092.56,315.948C1086.59,315.948 1081.46,313.615 1077.17,308.949C1072.93,304.158 1070.82,298.373 1070.82,291.591C1070.82,284.81 1072.93,279.055 1077.17,274.327C1081.46,269.599 1086.59,267.234 1092.56,267.234C1095.8,267.234 1098.8,267.934 1101.57,269.334C1104.34,270.734 1106.53,272.647 1108.15,275.073L1108.52,275.073L1108.52,268.728L1116.73,268.728L1116.73,312.495C1116.73,319.836 1114.65,325.591 1110.48,329.76C1106.25,333.99 1100.65,336.105 1093.68,336.105Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <rect x="1127.19" y="281.979" width="29.863" height="7.092" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></rect> <path d="M1193.26,258.182L1182.34,288.325L1204.55,288.325L1193.63,258.182L1193.26,258.182ZM1172.91,314.455L1163.39,314.455L1188.59,247.637L1198.3,247.637L1223.49,314.455L1213.98,314.455L1207.54,296.351L1179.45,296.351L1172.91,314.455Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1229.84,268.728L1238.05,268.728L1238.05,275.073L1238.42,275.073C1239.73,272.834 1241.74,270.967 1244.44,269.474C1247.15,267.981 1249.97,267.234 1252.89,267.234C1258.49,267.234 1262.8,268.836 1265.82,272.04C1268.83,275.244 1270.34,279.802 1270.34,285.712L1270.34,314.455L1261.76,314.455L1261.76,286.272C1261.57,278.806 1257.8,275.073 1250.46,275.073C1247.04,275.073 1244.18,276.458 1241.88,279.226C1239.58,281.995 1238.42,285.308 1238.42,289.165L1238.42,314.455L1229.84,314.455L1229.84,268.728Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1300.48,308.109C1304.71,308.109 1308.17,306.585 1310.84,303.536C1313.64,300.488 1315.04,296.506 1315.04,291.591C1315.04,286.801 1313.64,282.85 1310.84,279.739C1308.11,276.629 1304.65,275.073 1300.48,275.073C1296.38,275.073 1292.92,276.629 1290.12,279.739C1287.33,282.85 1285.92,286.801 1285.92,291.591C1285.92,296.444 1287.33,300.395 1290.12,303.443C1292.92,306.554 1296.38,308.109 1300.48,308.109ZM1300.2,336.105C1297.65,336.105 1295.26,335.779 1293.02,335.126C1290.78,334.472 1288.74,333.555 1286.9,332.373C1285.07,331.191 1283.5,329.791 1282.19,328.173C1280.89,326.556 1279.89,324.751 1279.21,322.761L1287.33,319.401C1288.26,322.076 1289.88,324.223 1292.18,325.84C1294.48,327.458 1297.15,328.266 1300.2,328.266C1304.87,328.266 1308.51,326.867 1311.12,324.067C1313.74,321.267 1315.04,317.41 1315.04,312.495L1315.04,308.109L1314.67,308.109C1313.05,310.535 1310.86,312.449 1308.09,313.848C1305.32,315.248 1302.32,315.948 1299.08,315.948C1293.11,315.948 1287.98,313.615 1283.69,308.949C1279.45,304.158 1277.34,298.373 1277.34,291.591C1277.34,284.81 1279.45,279.055 1283.69,274.327C1287.98,269.599 1293.11,267.234 1299.08,267.234C1302.32,267.234 1305.32,267.934 1308.09,269.334C1310.86,270.734 1313.05,272.647 1314.67,275.073L1315.04,275.073L1315.04,268.728L1323.25,268.728L1323.25,312.495C1323.25,319.836 1321.17,325.591 1317,329.76C1312.77,333.99 1307.17,336.105 1300.2,336.105Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path></g></svg></div> <ul class="divide-y font-light" data-v-1a4f42dc><li data-v-1a4f42dc><a href="/about" class="text-gray-500 my-4 inline-block poppins" data-v-1a4f42dc>About</a></li> <li data-v-1a4f42dc><a href="/all-articles" class="text-gray-500 my-4 inline-block poppins" data-v-1a4f42dc>Articles</a></li> <li data-v-1a4f42dc><a href="/categories" class="text-gray-500 my-4 inline-block poppins" data-v-1a4f42dc>Categories</a></li> <li data-v-1a4f42dc><a href="/members" class="text-gray-500 my-4 inline-block poppins" data-v-1a4f42dc>Members</a></li> <li data-v-1a4f42dc><a href="/projects" class="text-gray-500 my-4 inline-block poppins" data-v-1a4f42dc>Projects</a></li></ul> <div class="flex items-center justify-center" data-v-1a4f42dc><div class="social flex space-x-6 mt-6" data-v-1a4f42dc><a href="https://github.com/GDSC-CAU" target="blank" data-v-1a4f42dc><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current text-gray-300 w-auto md:block h-6 octcat-color w-6 h-6" data-v-696fe586 data-v-1a4f42dc><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" data-v-696fe586></path></svg></a> <a href="https://gdsc-cau.notion.site/GDSC-CAU-Member-Space-a8f22210d95a4e439dfae3a45b04ceb2" target="blank" data-v-1a4f42dc><svg xmlns="http://www.w3.org/2000/svg" viewBox="12 0.18999999999999906 487.619 510.941" class="fill-current text-gray-300 w-auto md:block h-5 octcat-color w-6 h-6" data-v-064e0d9e data-v-1a4f42dc><path d="M96.085 91.118c15.81 12.845 21.741 11.865 51.43 9.884l279.888-16.806c5.936 0 1-5.922-.98-6.906L379.94 43.686c-8.907-6.915-20.773-14.834-43.516-12.853L65.408 50.6c-9.884.98-11.858 5.922-7.922 9.883zm16.804 65.228v294.491c0 15.827 7.909 21.748 25.71 20.769l307.597-17.799c17.81-.979 19.794-11.865 19.794-24.722V136.57c0-12.836-4.938-19.758-15.84-18.77l-321.442 18.77c-11.863.997-15.82 6.931-15.82 19.776zm303.659 15.797c1.972 8.903 0 17.798-8.92 18.799l-14.82 2.953v217.412c-12.868 6.916-24.734 10.87-34.622 10.87-15.831 0-19.796-4.945-31.654-19.76l-96.944-152.19v147.248l30.677 6.922s0 17.78-24.75 17.78l-68.23 3.958c-1.982-3.958 0-13.832 6.921-15.81l17.805-4.935V210.7l-24.721-1.981c-1.983-8.903 2.955-21.74 16.812-22.736l73.195-4.934 100.889 154.171V198.836l-25.723-2.952c-1.974-10.884 5.927-18.787 15.819-19.767zM42.653 23.919l281.9-20.76c34.618-2.969 43.525-.98 65.283 14.825l89.986 63.247c14.848 10.876 19.797 13.837 19.797 25.693v346.883c0 21.74-7.92 34.597-35.608 36.564L136.64 510.14c-20.785.991-30.677-1.971-41.562-15.815l-66.267-85.978C16.938 392.52 12 380.68 12 366.828V58.495c0-17.778 7.922-32.608 30.653-34.576z" fill-rule="evenodd" data-v-064e0d9e></path></svg></a></div></div></aside></div></div> <div class="w-full bg-gray-50 bg-gray-50 px-0 md:px-5"><div class="related max-w-5xl mx-auto pt-28 pb-12 md:pb-24 md:pt-44"><div class="max-w-3xl mx-auto"><p class="text-base md:text-xl text-gray-400 text-center mb-2"><a href="/Data-Science" class="hover:underline">
                    Data-Science
                </a></p> <p class="custom-text leading-snug md:leading-normal px-5 md:px-0 mb-2 text-2xl md:text-5xl text-center text-gray-800 title font-semibold">MNIST로 보는 분류(Classification)</p> <p class="text-base md:text-xl text-gray-500 text-center mb-16">
                by
                <span><a href="/members/yujin-son" class="hover:underline">
                        YuJin Son
                    </a></span></p></div> <div class="prose max-w-5xl custom-text px-6 nuxt-content"><h1 id="ch3-classification"><a href="#ch3-classification" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>CH3. Classification</h1>
<p><strong><strong><strong>CHACTPER 1) mentioned [most common supervised learning tasks are regression(predicting values) and classification(predicting classes)</strong></strong></strong></p>
<p><strong><strong><strong>CHACTPER 2) regression task, predicting housing values, using various algorithms such as Linear Regression, Deicision Trees, and Random Forests</strong></strong></strong></p>
<p><strong>In ChACTPER 3 ⇒ “CLASSIFICATION”</strong></p>
<h1 id="참조-사이트"><a href="#%EC%B0%B8%EC%A1%B0-%EC%82%AC%EC%9D%B4%ED%8A%B8" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>참조 사이트</h1>
<p><a href="https://www.notion.so/CH3-Classification-c66704b5772444dcb144decb74b698b3" rel="nofollow noopener noreferrer" target="_blank">https://www.notion.so/CH3-Classification-c66704b5772444dcb144decb74b698b3</a></p>
<p><a href="https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb" rel="nofollow noopener noreferrer" target="_blank">handson-ml2/03_classification.ipynb at master · ageron/handson-ml2</a></p>
<h1 id="chapter-2-end-to-end-machine-learning-project"><a href="#chapter-2-end-to-end-machine-learning-project" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a><strong>CHAPTER 2) End-to-End Machine Learning Project</strong></h1>
<h2 id="1-mnist"><a href="#1-mnist" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>1. MNIST</h2>
<ul>
<li><strong>MNIST dataset</strong> : a set of 70,000 <strong>small images of digits handwritten</strong> by high school and employees of the US Census Bureau. / each image is labeled with the digit it represents</li>
</ul>
<p><img alt="MNIST" src="/ai_ml-study-ch3/01.png"></p>
<p>⇒ Machine Learning 계의 “Hello World” 같은 존재 /</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openml
mnist <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span><span class="token string">'mnist_784'</span><span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
mnist<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="MNIST dataset" src="/ai_ml-study-ch3/02.png"></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>X, y= mnist["data"], mnist["target"]
X.shape
=> (70000, 784)
</code></pre></div>
<p>:  <strong>70,000 images, and each images has 784(28x28 pixels) features.</strong></p>
<p>: one pixels’s intensity( 0(white) ~ 255(black))</p>
<ul>
<li><strong><strong><strong><strong><strong>data</strong></strong></strong></strong></strong> key :  containing <strong>an array with one row per instance and one column per feature.</strong></li>
<li><strong><strong><strong><strong><strong><strong>target</strong></strong></strong></strong></strong></strong> key : containing an <strong>array with the labels.</strong></li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>y.shpae
=> (70000,)
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">import</span> matplotlib <span class="token keyword">as</span> mpl
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

some_digit <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
some_digit_image <span class="token operator">=</span> some_digit<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>some_digit_image<span class="token punctuation">,</span> cmap<span class="token operator">=</span>mpl<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>binary<span class="token punctuation">,</span> interpolation<span class="token operator">=</span><span class="token string">"nearest"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="MNIST 5" src="/ai_ml-study-ch3/03.png">
: look like 5</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  
<span class="token operator">=</span><span class="token operator">></span> <span class="token string">'5'</span>
</code></pre></div>
<p>: indeed that's what the label tell us</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y <span class="token operator">=</span> y<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span> 
</code></pre></div>
<p>: label : string -> integer</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">60000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token number">60000</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">60000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span><span class="token number">60000</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
</code></pre></div>
<p>: always <strong>create a test set</strong> and <strong>set it aside before inspecting the data</strong> closely.</p>
<p>: <strong>split into a training set</strong>(the first 60,000 images) and a test set(the last 10,000 images )</p>
<ul>
<li>The training set is already shuffled for us, which is good as this guarantee that all cross-validatiof folds will be similar</li>
</ul>
<h2 id="2-training-a-binary-classifier이진-분류기-훈련"><a href="#2-training-a-binary-classifier%EC%9D%B4%EC%A7%84-%EB%B6%84%EB%A5%98%EA%B8%B0-%ED%9B%88%EB%A0%A8" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>2. Training a Binary Classifier(이진 분류기 훈련)</h2>
<p>[Problem]</p>
<p><strong>1) identify one digit</strong></p>
<p>: ex) 5-detector</p>
<p><strong><strong><strong>2)</strong></strong></strong> distinguishing between just two classes, <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>5 and not-5</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>y_train_5 = (y_train == 5)
y_test_5 = (y_test == 5)
</code></pre></div>
<p>: True(5) / False(all other digits)</p>
<ul>
<li><strong>PICK</strong> A CLASSIFIER AND <strong>TRAIN</strong> IT</li>
</ul>
<p>⇒ <strong>Stochastic Gradient Descent(SGD) classifier</strong> (확률적 경사 하강법)</p>
<p>using Scikit-Learn’s <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>SGDClassifier</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> class</p>
<p>😍<strong>Advantages</strong>😍 ****: being capable of <strong>handling very large datasets efficiently.</strong></p>
<p>: b/c SGD deals w/ t<strong>raining instances independently</strong>, one at a time(well suited for <strong>online learning</strong>)</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_modelimport SGDClassifier

sgd_clf<span class="token operator">=</span> SGDClassifier<span class="token punctuation">(</span>max_iter<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>
sgd_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train_5<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> SGDClassifier<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>
</code></pre></div>
<p>cf) <strong>SGDClassifier</strong> relies on <strong>randomness</strong> during training(hence the name ‘stochastic(확률론적)’). If we want reproducible results, you should set the <strong>random_state</strong> parameter.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>sgd_clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>some_digit<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>: The classifier guesses that this image represents  a 5 (true)</p>
<ul>
<li></li>
</ul>
<h2 id="3-performance-measures성능-측정"><a href="#3-performance-measures%EC%84%B1%EB%8A%A5-%EC%B8%A1%EC%A0%95" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>3. Performance Measures(성능 측정)</h2>
<p>: <strong>Evalutaing a classifier is often significantly trickier than evalutaing a regressor</strong></p>
<h3 id="3-1-measuring-accuracy-using-cross-validation교차-검증"><a href="#3-1-measuring-accuracy-using-cross-validation%EA%B5%90%EC%B0%A8-%EA%B2%80%EC%A6%9D" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>3-1. Measuring Accuracy Using Cross-Validation(교차 검증)</h3>
<ul>
<li><strong>Implementing Cross-Validation</strong></li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selectionimport <span class="token operator">**</span>StratifiedKFold<span class="token operator">**</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>baseimport clone

skfolds<span class="token operator">=</span> StratifiedKFold<span class="token punctuation">(</span>n_splits<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> train_index<span class="token punctuation">,</span> test_indexin skfolds<span class="token punctuation">.</span>split<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train_5<span class="token punctuation">)</span><span class="token punctuation">:</span>
    clone_clf<span class="token operator">=</span> clone<span class="token punctuation">(</span>sgd_clf<span class="token punctuation">)</span>
    X_train_folds<span class="token operator">=</span> X_train<span class="token punctuation">[</span>train_index<span class="token punctuation">]</span>
    y_train_folds<span class="token operator">=</span> y_train_5<span class="token punctuation">[</span>train_index<span class="token punctuation">]</span>
    X_test_fold<span class="token operator">=</span> X_train<span class="token punctuation">[</span>test_index<span class="token punctuation">]</span>
    y_test_fold<span class="token operator">=</span> y_train_5<span class="token punctuation">[</span>test_index<span class="token punctuation">]</span>

    clone_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_folds<span class="token punctuation">,</span> y_train_folds<span class="token punctuation">)</span>
    y_pred<span class="token operator">=</span> clone_clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test_fold<span class="token punctuation">)</span>
    n_correct<span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>y_pred<span class="token operator">==</span> y_test_fold<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>n_correct<span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token number">0.9669</span>
<span class="token number">0.91625</span>
<span class="token number">0.96785</span>
</code></pre></div>
<p>= roughly the same thing as <strong>Scikit-Learn’s cross_val_score()</strong> function, and prints the same result:</p>
<p><strong>StratifiedKFold :</strong> performs stratified(계층적) sampling to produce folds that contain a representative ratio of each class.</p>
<p>clone_clf= clone(sgd_clf)<strong>:</strong> At  each iteration the code creates a clone of the classifier, trains that clone on the training folds, and makes predicitons on the test fold.</p>
<p>⇒ counts the number of correct predictions and outputs the ratio of correct predictions.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score
cross_val_score<span class="token punctuation">(</span>sgd_clf<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_train_5<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.95035</span><span class="token punctuation">,</span> <span class="token number">0.96035</span><span class="token punctuation">,</span> <span class="token number">0.9604</span> <span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>: <strong><strong><strong><strong><strong><strong>cross_val_score()</strong></strong></strong></strong></strong></strong> function <strong>: evaluate</strong> your <strong>SGDClassifier model</strong> <strong>using K-fold cross-validation</strong>, with three folds. ************************</p>
<p>: **Above 93% accuracy(**ratio of correct predictions) on all cross-validation folds</p>
<p><strong>?????????????</strong></p>
<ul>
<li><strong>dumb classifier that just classifies every single image in the “not-5” class</strong></li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token operator">//</span><span class="token keyword">not</span><span class="token operator">-</span><span class="token number">5</span>

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>baseimport BaseEstimator
<span class="token keyword">class</span> <span class="token class-name">Never5Classifier</span><span class="token punctuation">(</span>BaseEstimator<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
passdef predict<span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token keyword">return</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">bool</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>never_5_clf <span class="token operator">=</span> Never5Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
cross_val_score<span class="token punctuation">(</span>never_5_clf<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_train_5<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.91125</span><span class="token punctuation">,</span> <span class="token number">0.90855</span><span class="token punctuation">,</span> <span class="token number">0.90915</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>: <strong>NOT-5 도 90% accuracy</strong></p>
<p><strong><strong><strong>⇒</strong></strong></strong> b/c about 10% of the images are 5s, ( 불균형한 dataset)</p>
<p>⇒ This demonstrates <strong>why accuracy is generally not the preferred performance measure for classifiers,</strong> especially when you are dealing with skewed datasest(정확도를 classifier의 성능 측정 지표로 선호하지 않음.)</p>
<h3 id="3-2-confusion-matirx오차-행렬"><a href="#3-2-confusion-matirx%EC%98%A4%EC%B0%A8-%ED%96%89%EB%A0%AC" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a><strong>3-2. Confusion Matirx(오차 행렬)</strong></h3>
<p>⇒ <strong>much better way to evaluate the performance of a classifier</strong></p>
<p><strong>[The general idea]</strong></p>
<ul>
<li><strong>Count the # of times instances of class A are classified as class  B.</strong></li>
</ul>
<p>ex) the # of times the classifier confused images of 5s with 3s ⇒ look in the 5th row and 3rd column of the confusion matrix.(5행 3열)</p>
<ol>
<li><strong>predictions ⇒ can compared to the actual targets.</strong></li>
</ol>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selectionimport cross_val_predict

y_train_pred<span class="token operator">=</span> cross_val_predict<span class="token punctuation">(</span>sgd_clf<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_train_5<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
</code></pre></div>
<p>cross_val_predict :  <strong>perfoms K-fold cross-validation</strong>, <strong>returns the predictions</strong> made on each test fold ( returning the evaluation score (XXX))</p>
<p>⇒ can get a <strong>clean prediction</strong> for each instance in the training set</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix

confusion_matrix<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">53892</span><span class="token punctuation">,</span>   <span class="token number">687</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
          <span class="token punctuation">[</span> <span class="token number">1891</span><span class="token punctuation">,</span>  <span class="token number">3530</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>: <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>confusion_matrix()</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> function.</p>
<p>: y_train_5 : target classes</p>
<p>:  y_train_pred : predicted classes</p>
<ul>
<li><strong>row</strong> : actual class</li>
<li><strong>column</strong> : predicted class</li>
</ul>
<p>cf) negative(false) / positive(true)</p>
<ul>
<li><strong>The 1st row : non-5 images ( the negative class)</strong></li>
</ul>
<p>= 53,892 of them were <strong>correctly classified</strong> as non-5s <strong>( true negatives)</strong> ⇒ 5 아님으로 분류</p>
<p><strong><strong><strong><strong><strong><strong>while</strong></strong></strong></strong></strong></strong> 687 were <strong>wrongly classified</strong> as 5s <strong>(false positives) ⇒</strong> 5라고 잘못 분류</p>
<ul>
<li><strong>The 2rd row : images of 5s (the positive class)</strong></li>
</ul>
<p>= 1891 were <strong>wrongly classified as non-5(false negatives)</strong> ⇒ 5아님으로 잘못 분류</p>
<p><strong>while</strong> 3530 were <strong>correctly classified</strong> as <strong>5s(true positives)</strong> ⇒ 5라고 분류</p>
<p>⇒ A perfect classifier would have <strong>true positives</strong> || <strong>true negatives</strong></p>
<p>⇒ A perfect classifier would have <strong>nonzero values only on its main diagonal</strong> ( top left to bottom right)</p>
<ul>
<li><strong>pretend we reached perfection</strong></li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y_train_perfect_predictions <span class="token operator">=</span> y_train_5  <span class="token comment"># pretend we reached perfection</span>
confusion_matrix<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_train_perfect_predictions<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">54579</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span>    <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">5421</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<ul>
<li><strong>PRECISION ; the accuracy of the positive predictions</strong></li>
</ul>
<p>: prefer a <strong>more concise(간결한) metric</strong> than the confusion matrix</p>
<p><img alt="precision" src="/ai_ml-study-ch3/04.png"></p>
<ul>
<li><strong>TP</strong> : # of true positives</li>
<li><strong>FP</strong> : # of false positives</li>
</ul>
<p>⇒ A trivial way to have perfect precision : <strong>make one single positive prediction and ensure it is correct</strong></p>
<p>( precision = 1/1 = 100%)</p>
<p><strong><strong><strong><strong><strong>But, not very useful</strong></strong></strong></strong></strong> b/c the classifier would ignore all but one positive instance.</p>
<ul>
<li><strong>RECALL(=SENSITIVITY || TRUE POSITIVE RATE)</strong></li>
</ul>
<p>: <strong><strong><strong><strong><strong>precision is typically used along with recall b/c</strong></strong></strong></strong></strong> precision would <strong><strong><strong><strong><strong>not very useful</strong></strong></strong></strong></strong> b/c the classifier would ignore all but one positive instance.</p>
<p><img alt="recall" src="/ai_ml-study-ch3/05.png"></p>
<ul>
<li><strong>FN</strong> : # of false negatives</li>
</ul>
<p><img alt="An illustrated confusion matrix" src="/ai_ml-study-ch3/06.png"></p>
<h3 id="3-3-precision-and-recall정밀도와-재현율"><a href="#3-3-precision-and-recall%EC%A0%95%EB%B0%80%EB%8F%84%EC%99%80-%EC%9E%AC%ED%98%84%EC%9C%A8" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>3-3. Precision and Recall(정밀도와 재현율)</h3>
<ul>
<li>Scikit-Learn provieds several fuctions to compute classifier metrics, including precision and recall</li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> precision_score<span class="token punctuation">,</span> recall_score

precision_score<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> <span class="token number">0.8370879772350012</span>
</code></pre></div>
<p>// 5호 판별된 이미지 중 83%만 정확</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>recall_score<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> <span class="token number">0.6511713705958311</span>
</code></pre></div>
<p>// 전체 5에 대해 65%만 정확히 5로 감지</p>
<ul>
<li><strong>F1 score</strong> : the <strong>harmonic mean(조화평균) of precision and recall</strong></li>
</ul>
<p>: it is often convenient to <strong>combine precision and recall</strong> into a single metric</p>
<p>: especially, when compare two classifiers.</p>
<p>⇒gives much more <strong>weight to low values</strong></p>
<p><img alt="F1" src="/ai_ml-study-ch3/07.png"></p>
<ul>
<li>call <strong><strong><strong>f1_score()</strong></strong></strong> function to compute the F1 score.</li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> f1_score

f1_score<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span><span class="token number">0.7325171197343846</span>
</code></pre></div>
<p>⇒<strong>The F1 score favors</strong> classifiers that have <strong>similar precision and recall.</strong></p>
<p>ex) Unfortunately, we <strong>can’t have it both ways:</strong></p>
<p><strong>increasing precision reduces recall, and vice versa</strong>. This is called the <strong>precision/recall tradeoff.</strong></p>
<h3 id="3-4-precisionrecall-tradeoff"><a href="#3-4-precisionrecall-tradeoff" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>3-4. Precision/Recall Tradeoff</h3>
<ul>
<li><strong>how the SGDClassifier makes its classification decisions</strong></li>
</ul>
<p><img alt="Decision threshold and precision/recall tradeoff" src="/ai_ml-study-ch3/08.png"></p>
<p>⇒ decision function</p>
<ul>
<li><strong>score > threshold</strong> ⇒ assigns the instance to the <strong>positive class</strong></li>
<li><strong>score &lt; threshold</strong> ⇒ assigns the instance to the <strong>negative class</strong></li>
</ul>
<p>⇒ If you <strong>raise the threshold (move it to the arrow on the right)</strong></p>
<p><strong>→</strong> the false positive (the 6) becomes a true negative, thereby <strong>increasing precision</strong> (up to 100% in this case), but one true positive becomes a false negative, <strong>decreasing recall down</strong> to 50%.</p>
<p>⇒ Conversely, <strong>lowering the threshold increases recall and reduces precision.</strong></p>
<ul>
<li>Scikit-Learn <strong>does not let you set the threshold directly,</strong> but it gi<strong>ves us access to the decision scores</strong> that it uses to make predictions.</li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y_scores <span class="token operator">=</span> sgd_clf<span class="token punctuation">.</span><span class="token operator">**</span>decision_function<span class="token operator">**</span><span class="token punctuation">(</span><span class="token punctuation">[</span>some_digit<span class="token punctuation">]</span><span class="token punctuation">)</span>
y_scores

<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2164.22030239</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>: predict() method 대신, call <strong>decision_function()</strong> method ⇒ <strong>returns a score</strong> for each instance, and then make predictions based on those scores using an threshold we want.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token operator">**</span>threshold <span class="token operator">=</span> <span class="token number">0</span><span class="token operator">**</span>
y_some_digit_pred <span class="token operator">=</span> <span class="token punctuation">(</span>y_scores <span class="token operator">></span> threshold<span class="token punctuation">)</span>
y_some_digit_pred

<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>: <strong>SGDClassifier</strong> uses a <strong>threshold =0</strong> ⇒ previous code <strong>returns the same result as the predict() method</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>threshold <span class="token operator">=</span> <span class="token number">8000</span>
y_some_digit_pred <span class="token operator">=</span> <span class="token punctuation">(</span>y_scores <span class="token operator">></span> threshold<span class="token punctuation">)</span>
y_some_digit_pred

<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>: This confirms that <strong>raising the threshold ⇒ decrease recall.</strong></p>
<p>The image actually represents a 5, and the classifier detects it when the threshold is 0, but it misses it when the threshold is increased to 8,000.</p>
<ul>
<li><strong>decide which threshold to use(적절한 threshold 정하기)</strong></li>
</ul>
<p><strong>1) cross_val_predict()</strong> function : to <strong>get the scores</strong> of all instances in the training set</p>
<p><strong>2) specifying return decision scores</strong> instead of predictions</p>
<p><strong>3) precision_recall_curve() : compute precision and recall</strong> for all possible threshold</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y_scores <span class="token operator">=</span> cross_val_predict<span class="token punctuation">(</span>sgd_clf<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_train_5<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> method<span class="token operator">=</span><span class="token string">"decision_function"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> precision_recall_curve

precisions<span class="token punctuation">,</span> recalls<span class="token punctuation">,</span> thresholds <span class="token operator">=</span> precision_recall_curve<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_scores<span class="token punctuation">)</span>
</code></pre></div>
<p><strong>[ways select a good precision/recall tradeoff]</strong></p>
<ul>
<li><strong>plot precision and recall as functions</strong> of the threshold value <strong>using Matplotlib</strong></li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">def</span> <span class="token function">plot_precision_recall_vs_threshold</span><span class="token punctuation">(</span>precisions<span class="token punctuation">,</span> recalls<span class="token punctuation">,</span> thresholds<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>thresholds<span class="token punctuation">,</span> precisions<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"b--"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Precision"</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>thresholds<span class="token punctuation">,</span> recalls<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"g-"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Recall"</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">"center right"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span> <span class="token comment"># Not shown in the book</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Threshold"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>        <span class="token comment"># Not shown</span>
    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>                              <span class="token comment"># Not shown</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">50000</span><span class="token punctuation">,</span> <span class="token number">50000</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>             <span class="token comment"># Not shown</span>

recall_90_precision <span class="token operator">=</span> recalls<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>precisions <span class="token operator">>=</span> <span class="token number">0.90</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
threshold_90_precision <span class="token operator">=</span> thresholds<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>precisions <span class="token operator">>=</span> <span class="token number">0.90</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                                                                  <span class="token comment"># Not shown</span>
plot_precision_recall_vs_threshold<span class="token punctuation">(</span>precisions<span class="token punctuation">,</span> recalls<span class="token punctuation">,</span> thresholds<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>threshold_90_precision<span class="token punctuation">,</span> threshold_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"r:"</span><span class="token punctuation">)</span>                 <span class="token comment"># Not shown</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">50000</span><span class="token punctuation">,</span> threshold_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"r:"</span><span class="token punctuation">)</span>                                <span class="token comment"># Not shown</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">50000</span><span class="token punctuation">,</span> threshold_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>recall_90_precision<span class="token punctuation">,</span> recall_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"r:"</span><span class="token punctuation">)</span><span class="token comment"># Not shown</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>threshold_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"ro"</span><span class="token punctuation">)</span>                                             <span class="token comment"># Not shown</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>threshold_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>recall_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"ro"</span><span class="token punctuation">)</span>                             <span class="token comment"># Not shown</span>
<span class="token comment">#save_fig("precision_recall_vs_threshold_plot")                                              # Not shown</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre></div>
<p><img alt="threshold" src="/ai_ml-study-ch3/09.png"></p>
<p>⇒ why precision curve is bumpier(울퉁불퉁)?</p>
<p>: b/c  <strong>precision may sometimes go down when you raise the threshold</strong></p>
<p><strong>On the other hand, recall can only go down when the threshold is increased,</strong> which explains why its curve looks smooth.</p>
<ul>
<li><strong>plot</strong> <strong>precision directly against recall</strong></li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">def</span> <span class="token function">plot_precision_vs_recall</span><span class="token punctuation">(</span>precisions<span class="token punctuation">,</span> recalls<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>recalls<span class="token punctuation">,</span> precisions<span class="token punctuation">,</span> <span class="token string">"b-"</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Recall"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Precision"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plot_precision_vs_recall<span class="token punctuation">(</span>precisions<span class="token punctuation">,</span> recalls<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>recall_90_precision<span class="token punctuation">,</span> recall_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"r:"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> recall_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"r:"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>recall_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"ro"</span><span class="token punctuation">)</span>
<span class="token comment">#save_fig("precision_vs_recall_plot")</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="recall" src="/ai_ml-study-ch3/10.png"></p>
<p>⇒ precision really starts to fall sharply around 80%(=0.8) recall.</p>
<p><strong>⇒ select a precision/recall tradeoff just before that drop</strong></p>
<p>⇒ Aim : 90% precision</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>threshold_90_precision <span class="token operator">=</span> thresholds<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>precisions <span class="token operator">>=</span> <span class="token number">0.90</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
threshold_90_precision

<span class="token operator">=</span><span class="token operator">></span> <span class="token number">3370.0194991439557</span>
</code></pre></div>
<p>: <strong>np.argmax() :</strong>  give us the <strong>first index of the maximum value</strong>, which in this case means the <strong>first True value</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y_train_pred_90 <span class="token operator">=</span> <span class="token punctuation">(</span>y_scores <span class="token operator">>=</span> threshold_90_precision<span class="token punctuation">)</span>
</code></pre></div>
<p>: To makek predictions, instead of calling the classifier’s <strong>predict()</strong> method</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>precision_score<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_train_pred_90<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> <span class="token number">0.9000345901072293</span>
</code></pre></div>
<p>: 90% precision classifier.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>recall_score<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_train_pred_90<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> <span class="token number">0.4799852425751706</span>
</code></pre></div>
<p>⇒ it is fairly <strong>easy</strong> to <strong>create a classifier</strong> with virtually <strong>any precision you want</strong>: just <strong>set a high enough threshold</strong>.</p>
<p>⇒  <strong>A high-precision classifier is not very useful if its recall is too low</strong></p>
<p>cf)  If someone says “let’s reach 99% precision,” you should ask, “at what recall?”</p>
<p><strong>sdfSE ; Root Mean Square Error</strong> (typical performance measure for regression problems)</p>
<p>: how much error the system typically makes in its prediction, with a higher weight for large errors.</p>
<p><img alt="RMSE" src="/ai_ml-study-ch3/11.png"></p>
<ul>
<li><strong><strong><strong>MAE ; Mean Absolute Error = Average Absolute Deviation</strong></strong></strong></li>
</ul>
<p>: <strong><strong>ex)</strong></strong> suppose that there are many outlier districts.</p>
<p><img alt="MAE" src="/ai_ml-study-ch3/12.png"></p>
<ul>
<li>
<p>both are ways to measure the distance between two vectors : the vector of predictions and the vector of target values. Various distance measures, or norms are possible.</p>
<h2 id="notations"><a href="#notations" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Notations</h2>
</li>
</ul>
<h3 id="3-5-the-roc-curve"><a href="#3-5-the-roc-curve" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>3-5. The ROC Curve</h3>
<ul>
<li><strong>ROC(receiver operating characteristic) curve(수신기 조작 특성 곡선)</strong> : common tool used with binary classifiers.</li>
</ul>
<p>⇒ plots <strong>the true positive rate (</strong> another name for recall) <strong>against the false positive rate</strong></p>
<p>⇒ <strong><strong><strong><strong><strong><strong>FPR (거짓 양성 비율):</strong></strong></strong></strong></strong></strong> the ratio of negative instances that are incorrectly classified as positive. (= 1 - true negative rate)</p>
<p>⇒ <strong><strong><strong>TPR(=specificity)(진짜 양성 비율) :</strong></strong></strong> the ratio of negative instances are correctly classified as negative.</p>
<p><strong>⇒ sensitivity(recall) VS 1 - specificity</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_curve

fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> thresholds <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_scores<span class="token punctuation">)</span>
</code></pre></div>
<p>: <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>roc_cureve()</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> function : <strong>compute the TPR and FPR for various threshold values</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">def</span> <span class="token function">plot_roc_curve</span><span class="token punctuation">(</span>fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'k--'</span><span class="token punctuation">)</span> <span class="token comment"># dashed diagonal</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                                    <span class="token comment"># Not shown in the book</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'False Positive Rate (Fall-Out)'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span> <span class="token comment"># Not shown</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'True Positive Rate (Recall)'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>    <span class="token comment"># Not shown</span>
    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>                                            <span class="token comment"># Not shown</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                                    <span class="token comment"># Not shown</span>
plot_roc_curve<span class="token punctuation">(</span>fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">)</span>
fpr_90 <span class="token operator">=</span> fpr<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>tpr <span class="token operator">>=</span> recall_90_precision<span class="token punctuation">)</span><span class="token punctuation">]</span>           <span class="token comment"># Not shown</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>fpr_90<span class="token punctuation">,</span> fpr_90<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> recall_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"r:"</span><span class="token punctuation">)</span>   <span class="token comment"># Not shown</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> fpr_90<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>recall_90_precision<span class="token punctuation">,</span> recall_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"r:"</span><span class="token punctuation">)</span>  <span class="token comment"># Not shown</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>fpr_90<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>recall_90_precision<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"ro"</span><span class="token punctuation">)</span>               <span class="token comment"># Not shown</span>
save_fig<span class="token punctuation">(</span><span class="token string">"roc_curve_plot"</span><span class="token punctuation">)</span>                                    <span class="token comment"># Not shown</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="False Positive Rate" src="/ai_ml-study-ch3/13.png"></p>
<p>: plot the FPR against the TPR using Matplotlib</p>
<p><strong><strong>[ TradeOff ]</strong></strong></p>
<ul>
<li>the higher the recall (TPR), the more false positives(FPR) the classifier produces.</li>
<li>The dotted line = the ROC curve of a purely random classifier</li>
</ul>
<p><strong>: The good classifier</strong> stays as <strong>far away</strong> from that line as possible</p>
<ul>
<li><strong><strong><strong><strong><strong><strong><strong><strong><strong>AUC(Area Under the Curve) :</strong></strong></strong></strong></strong></strong></strong></strong></strong> One way to compare classifiers</li>
</ul>
<p>⇒ ROC의 AUC ==1 : Perfect classifier</p>
<p>⇒ ROC의 AUC == 0.5 : purely random classifier</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>from sklearn.metrics import roc_auc_score
roc_auc_score(y_train_5, y_scores)

=> 0.9604938554008616
</code></pre></div>
<p>cf)  ROC value :=: precision/recall(or PR) curve,</p>
<p>⇒ prefe<strong>r PR curve</strong> : whenever the <strong>positive class is rare</strong> or when c<strong>are about the false positives</strong></p>
<p>⇒ prefer <strong>ROC curve</strong> : <strong>few positives</strong>(ex. 5s) compared to the negatives(non-5s)</p>
<ul>
<li>
<p><strong>RandomForestClassifier</strong> ⇒ compare its ROC curve and ROC AUC score to the SGDClassifier</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier
forest_clf <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>
y_probas_forest <span class="token operator">=</span> cross_val_predict<span class="token punctuation">(</span>forest_clf<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_train_5<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
 method<span class="token operator">=</span><span class="token string">"predict_proba"</span><span class="token punctuation">)</span>
</code></pre></div>
<p>⇒ decision_function() 대신 <strong>predict_proba() method</strong>가 있음 : <strong>returns an array</strong> containing <strong>a row per instance</strong> and a <strong>column per class,</strong> esch <strong>containing the probability</strong> that the given instance belongs to the given class.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y_scores_forest <span class="token operator">=</span> y_probas_forest<span class="token punctuation">[</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
fpr_forest<span class="token punctuation">,</span> tpr_forest<span class="token punctuation">,</span> thresholds_forest <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_scores_forest<span class="token punctuation">)</span>
</code></pre></div>
<p>: To plot a <strong>ROC curve, need scores,</strong> not probabilites</p>
<p>⇒ SOLUTION : use the <strong>positive class’s probability as the score.</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"SGD"</span><span class="token punctuation">)</span>
plot_roc_curve<span class="token punctuation">(</span>fpr_forest<span class="token punctuation">,</span> tpr_forest<span class="token punctuation">,</span> <span class="token string">"Random Forest"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">"lower right"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="FPR vs Random Forest" src="/ai_ml-study-ch3/14.png"></p>
</li>
</ul>
<p>: <strong>RandomForestClassifier’s ROC curve looks much better</strong> than the SGDClassifier’s</p>
<p>= much closer to the top-left corner.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>roc_auc_score<span class="token punctuation">(</span>y_train_5<span class="token punctuation">,</span> y_scores_forest<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> <span class="token number">0.9983436731328145</span>
</code></pre></div>
<p>: ROC의 AUC score is also significantly better.</p>
<p>Otherwise, <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>the precision and recall scores : precision(99%) & recall(86.6%)</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<p><strong>[train binary classifiers]</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token operator">-</span> choose the appropriate metric
<span class="token operator">-</span> evaluate our classifier using cross<span class="token operator">-</span>validation
<span class="token operator">-</span> select the precision<span class="token operator">/</span>recall tradeoff that fits your nedds
<span class="token operator">-</span> compare various models using ROC curve <span class="token keyword">and</span> ROC AUC scores
</code></pre></div>
<h2 id="4-multiclass-classification다중-분류"><a href="#4-multiclass-classification%EB%8B%A4%EC%A4%91-%EB%B6%84%EB%A5%98" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>4. Multiclass classification(다중 분류)</h2>
<p>: Whereas <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>binary classifiers</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>  distinguish between <strong><strong><strong><strong>two classes,</strong></strong></strong></strong></p>
<p><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>multiclass classifiers(=multinomial classifiers)</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> can distinguish between <strong>more than two classes.</strong></p>
<ul>
<li>p<strong>erform multiclass classification using multiple binary classifiers.</strong></li>
</ul>
<p>ex) Create a system than can classify the digit images into 10 classes (from 0 to 9)</p>
<ol>
<li>
<p><strong>OvA(one-versus-all) strategy (= one-versus-the-rest) : train 10 binary classifiers, one for each digit</strong> (a 0-detector, a 1-detector, a 2-detector, and so on). Then when you want to classify an image, you <strong>get the decision score</strong> <strong>from each classifier</strong> for that image and you <strong>select the class</strong> whose classifier outputs the <strong>highest score.</strong></p>
<p><strong>-Advantages</strong></p>
<p>⇒ ****OvA is preferred fo<strong>r most binary classification algorithms</strong></p>
</li>
<li>
<p><strong>OvO(one-versus-one) strategy</strong> : train <strong>a binary classifier for every pair of digits:</strong> one to distinguish 0s and 1s, another to distinguish 0s and 2s, another for 1s and 2s, and so on. If there are N classes, you need to train <strong>N × (N – 1) / 2 classifiers.</strong></p>
<p><strong>-Advantages</strong></p>
</li>
</ol>
<p>⇒ ****each classifier only needs to be trained on the part of the training set for the two classes that it must distinguish</p>
<p>⇒ OvO is preferred since it is <strong>faster to train many classifiers on small training sets t</strong>han training few classifiers on large training sets. (like Some algorithms (such as Support Vector Machine classifiers) scale poorly with the size of the training set. )dd</p>
<p>: <strong>Scikit-Learn detects</strong> when you try to use a <strong>binary classification algorithm for a multi‐
class classification task</strong>, and it <strong>automatically runs OvA</strong> (except for SVM classifiers for
which it uses OvO).</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>sgd_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
sgd_clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>some_digit<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>uint8<span class="token punctuation">)</span>
</code></pre></div>
<p>: This cod<strong>e trains the SGDClassifier</strong> on the training set using the original target classes from <strong>0 to 9 (y_train)</strong>, <strong>instead of the 5-versus-all target classes(y_train_5). ⇒ makes prediction</strong></p>
<p>: <strong>Scikit-Learn</strong> actually <strong>trained 10 binary classifiers</strong>, <strong>got their decision scores</strong> for the
image, and <strong>selected the class with the highest score</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>//샘플당 10개의 score 반환
some_digit_scores = sgd_clf.decision_function([some_digit])
some_digit_scores
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>array([[-31893.03095419, -34419.69069632,  -9530.63950739,
          1823.73154031, -22320.14822878,  -1385.80478895,
        -26188.91070951, -16147.51323997,  -4604.35491274,
        -12050.767298  ]])
</code></pre></div>
<p>: <strong>decision_function()</strong>  method : to see indeed case, returns 10 scores, one per class</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>//가장 높은 점수가 class 3에 해당하는 값
np.argmax(some_digit_scores)

=>3

sgd_clf.classes_

=> array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)

sgd_clf.classes_[3]

=> 3
</code></pre></div>
<p>: The <strong>highest score</strong> is indeed the one <strong>corresponding to class 3</strong></p>
<p>: When a classifier is trained, it <strong>stores the list of target classes in its classes_ attribute,</strong> ordered by value. (e.g., the class at index 3 happens to be class 3), but in general you won’t be so lucky.</p>
<ul>
<li><strong>force ScikitLearn to use OvO or OvA ⇒ use OneVsOneClassifier</strong> or <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>OneVsRestClassifier</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> classes.</li>
</ul>
<p>: create an instance and pass a binary classifier to its constructor.(객체 생성시 전달)</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>multiclass <span class="token keyword">import</span> OneVsOneClassifier
ovo_clf <span class="token operator">=</span> OneVsOneClassifier<span class="token punctuation">(</span>SGDClassifier<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
ovo_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
ovo_clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>some_digit<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>uint8<span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token builtin">len</span><span class="token punctuation">(</span>ovo_clf<span class="token punctuation">.</span>estimators_<span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> <span class="token number">45</span>
</code></pre></div>
<p>: create a multiclass classifier using the <strong>OvO strategy</strong>, based on <strong>SGDClassifier</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>forest_clf.fit(X_train, y_train)
forest_clf.predict([some_digit])

=> array([5], dtype=uint8)
</code></pre></div>
<p>: training <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>RandomForestClassifier</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<p>: This time <strong>Scikit-Learn did not have to run OvA or OvO</strong> because <strong>Random Forest
classifiers</strong> can <strong>directly classify instances into multiple classes.</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>forest_clf.**predict_proba**([some_digit])

=> array([[0.  , 0.  , 0.01, 0.08, 0.  , 0.9 , 0.  , 0.  , 0.  , 0.01]])
</code></pre></div>
<p>: <strong>predict_proba() :</strong>  <strong>get the list of probabilites</strong> that the classifier assigned to each instance for each class</p>
<p>⇒ the classifier is <strong>fairly confident</strong> <strong>about its prediction</strong></p>
<p><strong>:</strong> the 0.9 at the 5th index in the array means that the model estimates a <strong>90% probability</strong> that the image represents a 5.</p>
<ul>
<li><strong>evaluate these classifiers ⇒ use cross-validation</strong></li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring="accuracy")

=> 
</code></pre></div>
<p>: evaluate <strong>SGDClassifier’s</strong> accuracy using the <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>cross_val_score()</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p>
<p>: gets over <strong>84% on all test folds.</strong></p>
<p>: If you used a <strong>random classifier</strong>, you would get <strong>10% accuracy</strong>, so this is <strong>not such a bad scor</strong>e, but you can <strong>still do much better.</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>from sklearn.preprocessingimport StandardScaler
scaler= StandardScaler()
X_train_scaled= scaler.fit_transform(X_train.astype(np.float64))
cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring="accuracy")

=> array([0.8983, 0.891 , 0.9018])
</code></pre></div>
<p>: <strong>scaling</strong> the <strong>inputs increases accuracy</strong> above <strong>89%</strong></p>
<h2 id="5-error-analysis"><a href="#5-error-analysis" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>5. Error Analysis</h2>
<p>: Assume that you have <strong>found a promising model</strong> and you <strong>want to find ways to improve it</strong>.</p>
<p><strong>1. Analyze the types of errors it makes</strong></p>
<ul>
<li>confusion matrix</li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y_train_pred<span class="token operator">=</span> <span class="token operator">**</span>cross_val_predict<span class="token operator">**</span><span class="token punctuation">(</span>sgd_clf<span class="token punctuation">,</span> X_train_scaled<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
conf_mx<span class="token operator">=</span> <span class="token operator">**</span>confusion_matrix<span class="token operator">**</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span>
conf_mx
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5577</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">,</span>   <span class="token number">22</span><span class="token punctuation">,</span>    <span class="token number">5</span><span class="token punctuation">,</span>    <span class="token number">8</span><span class="token punctuation">,</span>   <span class="token number">43</span><span class="token punctuation">,</span>   <span class="token number">36</span><span class="token punctuation">,</span>    <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">225</span><span class="token punctuation">,</span>    <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6400</span><span class="token punctuation">,</span>   <span class="token number">37</span><span class="token punctuation">,</span>   <span class="token number">24</span><span class="token punctuation">,</span>    <span class="token number">4</span><span class="token punctuation">,</span>   <span class="token number">44</span><span class="token punctuation">,</span>    <span class="token number">4</span><span class="token punctuation">,</span>    <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">212</span><span class="token punctuation">,</span>   <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>  <span class="token number">27</span><span class="token punctuation">,</span>   <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">5220</span><span class="token punctuation">,</span>   <span class="token number">92</span><span class="token punctuation">,</span>   <span class="token number">73</span><span class="token punctuation">,</span>   <span class="token number">27</span><span class="token punctuation">,</span>   <span class="token number">67</span><span class="token punctuation">,</span>   <span class="token number">36</span><span class="token punctuation">,</span>  <span class="token number">378</span><span class="token punctuation">,</span>   <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>  <span class="token number">22</span><span class="token punctuation">,</span>   <span class="token number">17</span><span class="token punctuation">,</span>  <span class="token number">117</span><span class="token punctuation">,</span> <span class="token number">5227</span><span class="token punctuation">,</span>    <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">203</span><span class="token punctuation">,</span>   <span class="token number">27</span><span class="token punctuation">,</span>   <span class="token number">40</span><span class="token punctuation">,</span>  <span class="token number">403</span><span class="token punctuation">,</span>   <span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>  <span class="token number">12</span><span class="token punctuation">,</span>   <span class="token number">14</span><span class="token punctuation">,</span>   <span class="token number">41</span><span class="token punctuation">,</span>    <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">5182</span><span class="token punctuation">,</span>   <span class="token number">12</span><span class="token punctuation">,</span>   <span class="token number">34</span><span class="token punctuation">,</span>   <span class="token number">27</span><span class="token punctuation">,</span>  <span class="token number">347</span><span class="token punctuation">,</span>  <span class="token number">164</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>  <span class="token number">27</span><span class="token punctuation">,</span>   <span class="token number">15</span><span class="token punctuation">,</span>   <span class="token number">30</span><span class="token punctuation">,</span>  <span class="token number">168</span><span class="token punctuation">,</span>   <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">4444</span><span class="token punctuation">,</span>   <span class="token number">75</span><span class="token punctuation">,</span>   <span class="token number">14</span><span class="token punctuation">,</span>  <span class="token number">535</span><span class="token punctuation">,</span>   <span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>  <span class="token number">30</span><span class="token punctuation">,</span>   <span class="token number">15</span><span class="token punctuation">,</span>   <span class="token number">42</span><span class="token punctuation">,</span>    <span class="token number">3</span><span class="token punctuation">,</span>   <span class="token number">44</span><span class="token punctuation">,</span>   <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">5552</span><span class="token punctuation">,</span>    <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">131</span><span class="token punctuation">,</span>    <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>  <span class="token number">21</span><span class="token punctuation">,</span>   <span class="token number">10</span><span class="token punctuation">,</span>   <span class="token number">51</span><span class="token punctuation">,</span>   <span class="token number">30</span><span class="token punctuation">,</span>   <span class="token number">49</span><span class="token punctuation">,</span>   <span class="token number">12</span><span class="token punctuation">,</span>    <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5684</span><span class="token punctuation">,</span>  <span class="token number">195</span><span class="token punctuation">,</span>  <span class="token number">210</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>  <span class="token number">17</span><span class="token punctuation">,</span>   <span class="token number">63</span><span class="token punctuation">,</span>   <span class="token number">48</span><span class="token punctuation">,</span>   <span class="token number">86</span><span class="token punctuation">,</span>    <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">126</span><span class="token punctuation">,</span>   <span class="token number">25</span><span class="token punctuation">,</span>   <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5429</span><span class="token punctuation">,</span>   <span class="token number">44</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span>  <span class="token number">25</span><span class="token punctuation">,</span>   <span class="token number">18</span><span class="token punctuation">,</span>   <span class="token number">30</span><span class="token punctuation">,</span>   <span class="token number">64</span><span class="token punctuation">,</span>  <span class="token number">118</span><span class="token punctuation">,</span>   <span class="token number">36</span><span class="token punctuation">,</span>    <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">179</span><span class="token punctuation">,</span>  <span class="token number">371</span><span class="token punctuation">,</span> <span class="token number">5107</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>: need to <strong>make predictions</strong> using the <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>cross_val_predict()</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> function, then <strong>call the confusion_matrix()</strong> function</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token comment"># since sklearn 0.22, you can use sklearn.metrics.plot_confusion_matrix()</span>
<span class="token keyword">def</span> <span class="token function">plot_confusion_matrix</span><span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""If you prefer color and a colorbar"""</span>
    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">)</span>
    cax <span class="token operator">=</span> ax<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>matrix<span class="token punctuation">)</span>
    fig<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span>cax<span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>conf_mx<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>gray<span class="token punctuation">)</span>
save_fig<span class="token punctuation">(</span><span class="token string">"confusion_matrix_plot"</span><span class="token punctuation">,</span> tight_layout<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="confusion matrix" src="/ai_ml-study-ch3/15.png"></p>
<p>: more convenient to look at an <strong>image representation</strong> of the confusion matrix, using Matplotlib’s <strong><strong><strong><strong><strong><strong>matshow()</strong></strong></strong></strong></strong></strong> function</p>
<p>⇒ This confusion matrix looks fairly good, since most images are on the main diagonal,
which means that they were classified correctly.</p>
<p>⇒ The <strong>5s look slightly darke</strong>r than the other digits = there are <strong>fewer images of 5s</strong> in the dataset <strong>or</strong> that the <strong>classifier does not perform as well on 5s</strong> as on other digits.</p>
<p><strong>[FOCUS the plot on the ERRORS]</strong></p>
<ol>
<li><strong>divide each value in the confusion matrix by the number of images</strong> in the corresponding class ⇒ <strong>compare error rates</strong> instead of absolute number of errors (which would make abundant classes look unfairly bad):</li>
</ol>
<p>(오차 행렬의 값을 대응되는 클래스의 이미지 개수로 나누어 에러 비율 비교)</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>row_sums<span class="token operator">=</span> conf_mx<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
norm_conf_mx<span class="token operator">=</span> conf_mx<span class="token operator">/</span> row_sums
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>np<span class="token punctuation">.</span>fill_diagonal<span class="token punctuation">(</span>norm_conf_mx<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>norm_conf_mx<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>gray<span class="token punctuation">)</span>
<span class="token comment">#save_fig("confusion_matrix_errors_plot", tight_layout=False)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="confusion matrix focus on errors" src="/ai_ml-study-ch3/16.png"></p>
<p>: fill the diagonal w/ zeros to keep only the errors, and plot the result</p>
<p>⇒The <strong>column(predicted classes)<strong>for <strong>class 8 is quite bright,</strong> = many image</strong>s get misclassified as 8s.</strong></p>
<p>⇒ the <strong>row(actual classes) for class 8</strong> is <strong>not that bad</strong> = actual 8s in general <strong>get properly classified as 8s.</strong></p>
<p>⇒ 3s and 5s often get confused (in both directions).</p>
<p>→ <strong>Analyzing the confusion matrix</strong> can often give you <strong>insights</strong> on ways to <strong>improve your
classifier</strong></p>
<p>⇒ need to <strong>reduce the false 8s.</strong></p>
<p>: <strong>gather more training dat</strong>a for <strong>digits that look like 8s</strong> <strong>(but are not)</strong> → the classifier <strong>can learn to distinguish</strong> them from real 8s.
:  engineer <strong>new features</strong> <strong>that would help the classifier</strong>—ex) writing an algorithm to count the number of closed loops</p>
<p>: you could <strong>preprocess the images</strong> (e.g., using Scikit-Image, Pillow, or OpenCV) to make some patterns stand out more, such as closed loops.</p>
<p>→ <strong>Analyzing individual errors</strong> can also be a good way to gain <strong>insight</strong>s on <strong>what your
classifier is doin</strong>g and <strong>why it is failing</strong>, but it is more difficult and time-consuming</p>
<p>ex) <strong>plot examples of 3s and 5s</strong> (the <strong>plot_digits()</strong> function just uses Matplotlib’s <strong>imshow()</strong> function</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>cl_a<span class="token punctuation">,</span> cl_b <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span>
X_aa <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">(</span>y_train <span class="token operator">==</span> cl_a<span class="token punctuation">)</span> <span class="token operator">&</span> <span class="token punctuation">(</span>y_train_pred <span class="token operator">==</span> cl_a<span class="token punctuation">)</span><span class="token punctuation">]</span>
X_ab <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">(</span>y_train <span class="token operator">==</span> cl_a<span class="token punctuation">)</span> <span class="token operator">&</span> <span class="token punctuation">(</span>y_train_pred <span class="token operator">==</span> cl_b<span class="token punctuation">)</span><span class="token punctuation">]</span>
X_ba <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">(</span>y_train <span class="token operator">==</span> cl_b<span class="token punctuation">)</span> <span class="token operator">&</span> <span class="token punctuation">(</span>y_train_pred <span class="token operator">==</span> cl_a<span class="token punctuation">)</span><span class="token punctuation">]</span>
X_bb <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">(</span>y_train <span class="token operator">==</span> cl_b<span class="token punctuation">)</span> <span class="token operator">&</span> <span class="token punctuation">(</span>y_train_pred <span class="token operator">==</span> cl_b<span class="token punctuation">)</span><span class="token punctuation">]</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">221</span><span class="token punctuation">)</span><span class="token punctuation">;</span> plot_digits<span class="token punctuation">(</span>X_aa<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">,</span> images_per_row<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">222</span><span class="token punctuation">)</span><span class="token punctuation">;</span> plot_digits<span class="token punctuation">(</span>X_ab<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">,</span> images_per_row<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">223</span><span class="token punctuation">)</span><span class="token punctuation">;</span> plot_digits<span class="token punctuation">(</span>X_ba<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">,</span> images_per_row<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">;</span> plot_digits<span class="token punctuation">(</span>X_bb<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">,</span> images_per_row<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment">#save_fig("error_analysis_digits_plot")</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="MNIST 3s and 5s" src="/ai_ml-study-ch3/17.png"></p>
<p>:  숫자  3으로(5x5)         |   숫자 5로(5x5)                        : 잘 분류 된것들</p>
<p>분류된 것들 (5x5)        |  분류된 것들(5x5)                   : 잘 분류 하지 못한 것들</p>
<p>⇒ most <strong>misclassified images seem like obvious errors</strong> to us, and it’s <strong>hard to understand</strong> <strong>why the classifier made the mistakes</strong></p>
<p>: b/c we used a <strong>simple SGDClassifier</strong>, which is a <strong>linear model</strong>. All it does is <strong>assign a weight per class to each pixel</strong>, and when it sees a new image it just <strong>sums up the weighted pixel intensities</strong> to get a score for each class ⇒ So since <strong>3s and 5s differ only by a few pixels,</strong> this model will easily confuse them.</p>
<p>: this classifier is quite sensitive to image shifting and rotation</p>
<h2 id="6-multilabel-classification"><a href="#6-multilabel-classification" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>6. Multilabel Classification</h2>
<p>: Until now, each instance has always been assigned to just one class.</p>
<p>: In some cases you may want your <strong>classifier to output multiple classes for each instance.</strong></p>
<p>ex) <strong>face-recognition classifier</strong></p>
<p>:  attach <strong>one tag per person</strong> it recognizes. Say the classifier has been trained to recognize three faces, Alice, Bob, and Charlie; then when it is shown a picture of Alice and Charlie, it should output [1, 0, 1] (meaning “Alice yes, Bob no, Charlie yes”). Such a <strong>classification system that outputs multiple binary tags</strong> is called a multilabel classification system.</p>
<ul>
<li><strong>example for illustration purpose</strong></li>
</ul>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>from sklearn.neighbors import KNeighborsClassifier

y_train_large = (y_train >= 7)
y_train_odd = (y_train % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]

knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)
</code></pre></div>
<p>: creates a <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>y_multilabel</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> array containing <strong>two target labels for each digit image:</strong></p>
<p>⇒ 1.  indicates <strong>whether or not the digit is large (7, 8, or 9)</strong></p>
<p>⇒ 2. indicates <strong>whether or not it is odd</strong>.</p>
<p>: The next lines create a <strong>KNeighborsClassifier</strong> instance (which supports multilabel classification, but not all classifiers do) and <strong>train it using the multiple targets array. ⇒</strong> can make a <strong>prediction,</strong> and notice that it <strong>outputs two labels:</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>knnn_clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>some_digit<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p><strong>The digit 5</strong> is indeed <strong>not large (False)</strong> and <strong>odd (True)</strong></p>
<ul>
<li>There are <strong>many ways to evaluate a multilabel classifier,</strong> and <strong>selecting the right metric</strong></li>
</ul>
<p>really depends on your project.</p>
<p>⇒ 1 .one approach is to <strong>measure the F1 score for each individual label ⇒</strong>  then simply <strong>compute the average score</strong>.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>y_train_knn_pred <span class="token operator">=</span> cross_val_predict<span class="token punctuation">(</span>knn_clf<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_multilabel<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
f1_score<span class="token punctuation">(</span>y_multilabel<span class="token punctuation">,</span> y_train_knn_pred<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token string">"macro"</span><span class="token punctuation">)</span>

<span class="token operator">=</span><span class="token operator">></span><span class="token number">0.976410265560605</span>
</code></pre></div>
<p>: computes the <strong>average F1 score</strong> across all labels:</p>
<p>: This assumes that <strong>all labels are equally important</strong></p>
<ul>
<li>But, if you have many more pictures of Alice than of Bob or Charlie, you may want</li>
</ul>
<p>to <strong>give more weight to the classifier’s score</strong> on pictures of Alice. <strong>One simple option</strong> is
to <strong>give each label a weight equal</strong> to its support (i.e., the number of instances with that
target label). To do this, simpl<strong>y set average="weighted"</strong> in the preceding code.</p>
<h2 id="7-multioutput-classification"><a href="#7-multioutput-classification" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>7. Multioutput Classification</h2>
<ul>
<li><strong>generalization of multilabel classification</strong> <strong>where each label can be multiclass</strong> (i.e., it can have more than two possible values).</li>
<li><strong>ex ) Build a system that removes noise from images.</strong></li>
</ul>
<p>⇒ It will take as <strong>input a noisy digit image</strong>, and it will (hopefully) output <strong>a clean digit image,</strong> represented <strong>as an array of pixel intensities, just like the MNIST images.</strong></p>
<p>⇒ classifier’s output = <strong>multilabel</strong> (one label per pixel) & <strong>each label can have multiple values</strong> (pixel intensity ranges from 0 to 255).
: The line between classification and regression is sometimes blurry, such as in this example.</p>
<p>:  <strong>predicting pixel intensity</strong> is more <strong>akin to regression</strong> > classification</p>
<p>: multioutput systems are <strong>not limited to classification tasks;</strong> can have a system that outputs <strong>multiple labels</strong> per instance, including both c<strong>lass labels and value labels</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>noise <span class="token operator">=</span> <span class="token operator">**</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token operator">**</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X_train_mod <span class="token operator">=</span> X_train <span class="token operator">+</span> noise
noise <span class="token operator">=</span> <span class="token operator">**</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token operator">**</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X_test_mod <span class="token operator">=</span> X_test <span class="token operator">+</span> noise
y_train_mod <span class="token operator">=</span> X_train
y_test_mod <span class="token operator">=</span> X_test
</code></pre></div>
<p>:  <strong>NumPy’s randint()</strong> function : <strong>creating the training and test sets</strong> by taking the <strong>MNIST images</strong> and <strong>adding noise to their pixel intensitie</strong>s</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>some_index<span class="token operator">=</span> <span class="token number">0</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span><span class="token punctuation">;</span> plot_digit<span class="token punctuation">(</span>X_test_mod<span class="token punctuation">[</span>some_index<span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span><span class="token punctuation">;</span> plot_digit<span class="token punctuation">(</span>y_test_mod<span class="token punctuation">[</span>some_index<span class="token punctuation">]</span><span class="token punctuation">)</span>
save_fig<span class="token punctuation">(</span><span class="token string">"noisy_digit_example_plot"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="noisy input image" src="/ai_ml-study-ch3/18.png"></p>
<p>: left image = <strong>noisy input image</strong> / right image = <strong>clean target image</strong>.</p>
<p>⇒ <strong>train the classifier and make it clean this image</strong></p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>knn_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_mod<span class="token punctuation">,</span> y_train_mod<span class="token punctuation">)</span>
clean_digit<span class="token operator">=</span> knn_clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>X_test_mod<span class="token punctuation">[</span>some_index<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plot_digit<span class="token punctuation">(</span>clean_digit<span class="token punctuation">)</span>
save_fig<span class="token punctuation">(</span><span class="token string">"cleaned_digit_example_plot"</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="clean" src="/ai_ml-study-ch3/19.png"></p>
<p>: close enough to the target</p>
<p>should know <strong>how to select good metrics for classification tasks</strong>, <strong>pick the
appropriate precision/recall tradeoff, compare classifiers,</strong> and more generally <strong>build
good classification systems for a variety of tasks.</strong></p></div> <div class="max-w-6xl mx-auto px-5 flex justify-center pt-16 md:pt-20 pb-6 md:pb-20"><div><div class="box mb-4 md:mb-6 mx-auto"><img src="/_nuxt/img/yujin-son.dc852b3.jpg" alt class="profile"></div> <div class="text-gray-800 text-xl md:text-2xl pb-2 md:pb-3.5 font-medium flex justify-center poppins">YuJin Son</div> <div class="text-gray-500 text-sm md:text-base pb-3 md:pb-4 flex justify-center px-3 text-center custom-text">중앙대학교 소프트웨어학부 21학번입니다. GDSC 2기 멤버로 활동하고 있습니다.</div> <div class="flex justify-center itmes-center"><a href="/members/yujin-son" class="poppins text-blue-500 text-base md:text-lg hover:underline">
                        See More
                    </a></div></div></div> <div class="flex justify-between pt-12 px-3" data-v-d6278ec4><div class="w-5/12 ml-3 md:ml-0 bg-white md:bg-gray-50 hover:bg-white border border-gray-400 md:border-gray-300 hover:border-gray-400 rounded-lg md:rounded-xl p-3 md:px-8 md:py-6 group transition duration-300" data-v-d6278ec4><a href="/articles/ai_ml-study-ch1" data-v-d6278ec4><div class="text-center md:text-left text-gray-500" data-v-d6278ec4>Previous Post</div> <div class="hidden md:block text-gray-700 font-medium mt-1 custom-text" data-v-d6278ec4>머신러닝에 대해서</div></a></div> <div class="w-5/12 mr-3 md:mr-0 bg-white md:bg-gray-50 hover:bg-white border border-gray-400 md:border-gray-300 hover:border-gray-400 rounded-lg md:rounded-xl p-3 md:px-8 md:py-6 group transition duration-300" data-v-d6278ec4><a href="/articles/AI_study_ML_ch3" data-v-d6278ec4><div class="text-center md:text-right text-gray-500" data-v-d6278ec4>Next Post</div> <div class="hidden md:block text-right text-gray-700 font-medium mt-1 custom-text" data-v-d6278ec4>ML ch3 - classification</div></a></div></div></div></div> <footer class="w-full bg-gray-50 px-0 md:px-6"><div class="max-w-6xl mx-auto pt-11 pb-14 md:pt-11 md:pb-24 px-2 md:px-5 border-t border-gray-300 flex flex-col md:flex-row items-center justify-start md:justify-between"><div class="flex md:hidden justify-center items-center pb-9"><svg viewBox="0 0 2950 500" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" class="w-auto md:block h-6 h-4" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2" data-v-6b5b6345><g transform="matrix(1.04366,0,0,1.04366,3.30222,-10.9151)" data-v-6b5b6345><g transform="matrix(3.17657,0,0,3.17657,218.269,65.6614)" data-v-6b5b6345><path d="M0,56.813C0.104,56.853 0.22,56.845 0.317,56.791L36.566,36.501C45.134,31.707 48.229,20.712 43.48,11.947C38.73,3.181 27.937,-0.04 19.369,4.756L-42.813,39.56C-43.096,39.718 -43.065,40.144 -42.762,40.261L0,56.813Z" style="fill:#e84435;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,302.093,177.885)" data-v-6b5b6345><path d="M0,76.736C6.129,76.881 12.145,73.776 15.529,68.051C20.574,59.516 17.856,48.384 9.46,43.191L-52.188,5.052C-60.585,-0.145 -71.48,2.567 -76.525,11.102C-81.57,19.638 -78.853,30.768 -70.457,35.963L-8.808,74.101C-6.044,75.812 -3.008,76.665 0,76.736" style="fill:#2376e5;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,498.874,252.966)" data-v-6b5b6345><path d="M0,54.559C3.009,54.63 6.07,53.92 8.892,52.341L71.083,17.532C71.364,17.374 71.336,16.952 71.035,16.832L28.826,-0.029C28.722,-0.071 28.604,-0.064 28.506,-0.008L-8.306,20.595C-16.873,25.39 -19.969,36.384 -15.22,45.15C-12.034,51.03 -6.129,54.414 0,54.559" style="fill:#f6ba17;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,698.58,70.6884)" data-v-6b5b6345><path d="M0,76.734C6.13,76.879 12.145,73.776 15.529,68.049C20.574,59.514 17.856,48.384 9.46,43.189L-52.188,5.049C-60.584,-0.145 -71.479,2.563 -76.524,11.099C-81.569,19.634 -78.853,30.764 -70.456,35.96L-8.808,74.099C-6.044,75.809 -3.008,76.663 0,76.734" style="fill:#089d57;fill-rule:nonzero" data-v-6b5b6345></path></g></g> <g transform="matrix(4.0904,0,0,4.0904,-2519.11,-940.815)" data-v-6b5b6345><path d="M888.004,315.948C878.112,315.948 869.837,312.62 863.18,305.963C856.586,299.306 853.288,291 853.288,281.046C853.288,271.092 856.586,262.817 863.18,256.222C869.775,249.503 878.049,246.144 888.004,246.144C898.082,246.144 906.264,249.783 912.547,257.062L906.388,263.035C901.597,257.249 895.469,254.356 888.004,254.356C880.6,254.356 874.41,256.845 869.433,261.822C864.518,266.737 862.06,273.145 862.06,281.046C862.06,288.947 864.518,295.355 869.433,300.27C874.41,305.247 880.6,307.736 888.004,307.736C895.78,307.736 902.531,304.47 908.254,297.937L914.507,304.003C911.334,307.798 907.446,310.738 902.842,312.822C898.238,314.906 893.292,315.948 888.004,315.948Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M922.159,247.637L930.745,247.637L930.745,268.728L930.372,275.073L930.745,275.073C932.051,272.834 934.058,270.967 936.764,269.474C939.47,267.981 942.286,267.234 945.21,267.234C950.809,267.234 955.117,268.836 958.135,272.04C961.152,275.244 962.661,279.802 962.661,285.712L962.661,314.455L954.075,314.455L954.075,287.392C954.075,279.18 950.436,275.073 943.157,275.073C939.673,275.073 936.733,276.52 934.338,279.413C931.942,282.306 930.745,285.681 930.745,289.538L930.745,314.455L922.159,314.455L922.159,247.637Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1012.87,314.455L1004.65,314.455L1004.65,308.109L1004.28,308.109C1002.98,310.349 1000.97,312.215 998.263,313.708C995.556,315.201 992.741,315.948 989.817,315.948C984.218,315.948 979.91,314.346 976.892,311.142C973.875,307.938 972.366,303.381 972.366,297.47L972.366,268.728L980.952,268.728L980.952,296.911C981.138,304.376 984.902,308.109 992.243,308.109C995.665,308.109 998.527,306.725 1000.83,303.956C1003.13,301.188 1004.28,297.875 1004.28,294.018L1004.28,268.728L1012.87,268.728L1012.87,314.455Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1023.32,268.728L1031.53,268.728L1031.53,275.073L1031.9,275.073C1033.21,272.834 1035.22,270.967 1037.92,269.474C1040.63,267.981 1043.45,267.234 1046.37,267.234C1051.97,267.234 1056.28,268.836 1059.3,272.04C1062.31,275.244 1063.82,279.802 1063.82,285.712L1063.82,314.455L1055.24,314.455L1055.24,286.272C1055.05,278.806 1051.29,275.073 1043.94,275.073C1040.52,275.073 1037.66,276.458 1035.36,279.226C1033.06,281.995 1031.9,285.308 1031.9,289.165L1031.9,314.455L1023.32,314.455L1023.32,268.728Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1093.96,308.109C1098.19,308.109 1101.65,306.585 1104.32,303.536C1107.12,300.488 1108.52,296.506 1108.52,291.591C1108.52,286.801 1107.12,282.85 1104.32,279.739C1101.59,276.629 1098.13,275.073 1093.96,275.073C1089.86,275.073 1086.4,276.629 1083.61,279.739C1080.81,282.85 1079.4,286.801 1079.4,291.591C1079.4,296.444 1080.81,300.395 1083.61,303.443C1086.4,306.554 1089.86,308.109 1093.96,308.109ZM1093.68,336.105C1091.13,336.105 1088.74,335.779 1086.5,335.126C1084.26,334.472 1082.22,333.555 1080.38,332.373C1078.55,331.191 1076.98,329.791 1075.67,328.173C1074.37,326.556 1073.37,324.751 1072.69,322.761L1080.81,319.401C1081.74,322.076 1083.36,324.223 1085.66,325.84C1087.96,327.458 1090.63,328.266 1093.68,328.266C1098.35,328.266 1101.99,326.867 1104.6,324.067C1107.21,321.267 1108.52,317.41 1108.52,312.495L1108.52,308.109L1108.15,308.109C1106.53,310.535 1104.34,312.449 1101.57,313.848C1098.8,315.248 1095.8,315.948 1092.56,315.948C1086.59,315.948 1081.46,313.615 1077.17,308.949C1072.93,304.158 1070.82,298.373 1070.82,291.591C1070.82,284.81 1072.93,279.055 1077.17,274.327C1081.46,269.599 1086.59,267.234 1092.56,267.234C1095.8,267.234 1098.8,267.934 1101.57,269.334C1104.34,270.734 1106.53,272.647 1108.15,275.073L1108.52,275.073L1108.52,268.728L1116.73,268.728L1116.73,312.495C1116.73,319.836 1114.65,325.591 1110.48,329.76C1106.25,333.99 1100.65,336.105 1093.68,336.105Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <rect x="1127.19" y="281.979" width="29.863" height="7.092" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></rect> <path d="M1193.26,258.182L1182.34,288.325L1204.55,288.325L1193.63,258.182L1193.26,258.182ZM1172.91,314.455L1163.39,314.455L1188.59,247.637L1198.3,247.637L1223.49,314.455L1213.98,314.455L1207.54,296.351L1179.45,296.351L1172.91,314.455Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1229.84,268.728L1238.05,268.728L1238.05,275.073L1238.42,275.073C1239.73,272.834 1241.74,270.967 1244.44,269.474C1247.15,267.981 1249.97,267.234 1252.89,267.234C1258.49,267.234 1262.8,268.836 1265.82,272.04C1268.83,275.244 1270.34,279.802 1270.34,285.712L1270.34,314.455L1261.76,314.455L1261.76,286.272C1261.57,278.806 1257.8,275.073 1250.46,275.073C1247.04,275.073 1244.18,276.458 1241.88,279.226C1239.58,281.995 1238.42,285.308 1238.42,289.165L1238.42,314.455L1229.84,314.455L1229.84,268.728Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1300.48,308.109C1304.71,308.109 1308.17,306.585 1310.84,303.536C1313.64,300.488 1315.04,296.506 1315.04,291.591C1315.04,286.801 1313.64,282.85 1310.84,279.739C1308.11,276.629 1304.65,275.073 1300.48,275.073C1296.38,275.073 1292.92,276.629 1290.12,279.739C1287.33,282.85 1285.92,286.801 1285.92,291.591C1285.92,296.444 1287.33,300.395 1290.12,303.443C1292.92,306.554 1296.38,308.109 1300.48,308.109ZM1300.2,336.105C1297.65,336.105 1295.26,335.779 1293.02,335.126C1290.78,334.472 1288.74,333.555 1286.9,332.373C1285.07,331.191 1283.5,329.791 1282.19,328.173C1280.89,326.556 1279.89,324.751 1279.21,322.761L1287.33,319.401C1288.26,322.076 1289.88,324.223 1292.18,325.84C1294.48,327.458 1297.15,328.266 1300.2,328.266C1304.87,328.266 1308.51,326.867 1311.12,324.067C1313.74,321.267 1315.04,317.41 1315.04,312.495L1315.04,308.109L1314.67,308.109C1313.05,310.535 1310.86,312.449 1308.09,313.848C1305.32,315.248 1302.32,315.948 1299.08,315.948C1293.11,315.948 1287.98,313.615 1283.69,308.949C1279.45,304.158 1277.34,298.373 1277.34,291.591C1277.34,284.81 1279.45,279.055 1283.69,274.327C1287.98,269.599 1293.11,267.234 1299.08,267.234C1302.32,267.234 1305.32,267.934 1308.09,269.334C1310.86,270.734 1313.05,272.647 1314.67,275.073L1315.04,275.073L1315.04,268.728L1323.25,268.728L1323.25,312.495C1323.25,319.836 1321.17,325.591 1317,329.76C1312.77,333.99 1307.17,336.105 1300.2,336.105Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path></g></svg></div> <ul class="flex flex-col md:flex-row text-sm space-y-2 md:space-y-0"><li class="text-gray-500 mr-0 md:mr-3 flex justify-center"><a href="/" class="hover:underline nuxt-link-active">Blog</a></li> <li class="text-gray-500 mr-0 md:mr-3 flex justify-center"><a target="blank" href="https://github.com/GDSC-CAU" class="hover:underline">GitHub</a></li> <li class="text-gray-500 mr-0 md:mr-3 flex justify-center"><a target="blank" href="https://gdsc-cau.notion.site/GDSC-CAU-Member-Space-a8f22210d95a4e439dfae3a45b04ceb2" class="hover:underline">Notion</a></li> <li class="text-gray-500 mr-0 md:mr-3 flex justify-center"><a href="mailto:gdsc.cau@gmail.com" class="hover:underline">Email</a></li></ul> <div class="hidden md:flex justify-center items-center"><svg viewBox="0 0 2950 500" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" class="w-auto md:block h-6" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2" data-v-6b5b6345><g transform="matrix(1.04366,0,0,1.04366,3.30222,-10.9151)" data-v-6b5b6345><g transform="matrix(3.17657,0,0,3.17657,218.269,65.6614)" data-v-6b5b6345><path d="M0,56.813C0.104,56.853 0.22,56.845 0.317,56.791L36.566,36.501C45.134,31.707 48.229,20.712 43.48,11.947C38.73,3.181 27.937,-0.04 19.369,4.756L-42.813,39.56C-43.096,39.718 -43.065,40.144 -42.762,40.261L0,56.813Z" style="fill:#e84435;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,302.093,177.885)" data-v-6b5b6345><path d="M0,76.736C6.129,76.881 12.145,73.776 15.529,68.051C20.574,59.516 17.856,48.384 9.46,43.191L-52.188,5.052C-60.585,-0.145 -71.48,2.567 -76.525,11.102C-81.57,19.638 -78.853,30.768 -70.457,35.963L-8.808,74.101C-6.044,75.812 -3.008,76.665 0,76.736" style="fill:#2376e5;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,498.874,252.966)" data-v-6b5b6345><path d="M0,54.559C3.009,54.63 6.07,53.92 8.892,52.341L71.083,17.532C71.364,17.374 71.336,16.952 71.035,16.832L28.826,-0.029C28.722,-0.071 28.604,-0.064 28.506,-0.008L-8.306,20.595C-16.873,25.39 -19.969,36.384 -15.22,45.15C-12.034,51.03 -6.129,54.414 0,54.559" style="fill:#f6ba17;fill-rule:nonzero" data-v-6b5b6345></path></g> <g transform="matrix(3.17657,0,0,3.17657,698.58,70.6884)" data-v-6b5b6345><path d="M0,76.734C6.13,76.879 12.145,73.776 15.529,68.049C20.574,59.514 17.856,48.384 9.46,43.189L-52.188,5.049C-60.584,-0.145 -71.479,2.563 -76.524,11.099C-81.569,19.634 -78.853,30.764 -70.456,35.96L-8.808,74.099C-6.044,75.809 -3.008,76.663 0,76.734" style="fill:#089d57;fill-rule:nonzero" data-v-6b5b6345></path></g></g> <g transform="matrix(4.0904,0,0,4.0904,-2519.11,-940.815)" data-v-6b5b6345><path d="M888.004,315.948C878.112,315.948 869.837,312.62 863.18,305.963C856.586,299.306 853.288,291 853.288,281.046C853.288,271.092 856.586,262.817 863.18,256.222C869.775,249.503 878.049,246.144 888.004,246.144C898.082,246.144 906.264,249.783 912.547,257.062L906.388,263.035C901.597,257.249 895.469,254.356 888.004,254.356C880.6,254.356 874.41,256.845 869.433,261.822C864.518,266.737 862.06,273.145 862.06,281.046C862.06,288.947 864.518,295.355 869.433,300.27C874.41,305.247 880.6,307.736 888.004,307.736C895.78,307.736 902.531,304.47 908.254,297.937L914.507,304.003C911.334,307.798 907.446,310.738 902.842,312.822C898.238,314.906 893.292,315.948 888.004,315.948Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M922.159,247.637L930.745,247.637L930.745,268.728L930.372,275.073L930.745,275.073C932.051,272.834 934.058,270.967 936.764,269.474C939.47,267.981 942.286,267.234 945.21,267.234C950.809,267.234 955.117,268.836 958.135,272.04C961.152,275.244 962.661,279.802 962.661,285.712L962.661,314.455L954.075,314.455L954.075,287.392C954.075,279.18 950.436,275.073 943.157,275.073C939.673,275.073 936.733,276.52 934.338,279.413C931.942,282.306 930.745,285.681 930.745,289.538L930.745,314.455L922.159,314.455L922.159,247.637Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1012.87,314.455L1004.65,314.455L1004.65,308.109L1004.28,308.109C1002.98,310.349 1000.97,312.215 998.263,313.708C995.556,315.201 992.741,315.948 989.817,315.948C984.218,315.948 979.91,314.346 976.892,311.142C973.875,307.938 972.366,303.381 972.366,297.47L972.366,268.728L980.952,268.728L980.952,296.911C981.138,304.376 984.902,308.109 992.243,308.109C995.665,308.109 998.527,306.725 1000.83,303.956C1003.13,301.188 1004.28,297.875 1004.28,294.018L1004.28,268.728L1012.87,268.728L1012.87,314.455Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1023.32,268.728L1031.53,268.728L1031.53,275.073L1031.9,275.073C1033.21,272.834 1035.22,270.967 1037.92,269.474C1040.63,267.981 1043.45,267.234 1046.37,267.234C1051.97,267.234 1056.28,268.836 1059.3,272.04C1062.31,275.244 1063.82,279.802 1063.82,285.712L1063.82,314.455L1055.24,314.455L1055.24,286.272C1055.05,278.806 1051.29,275.073 1043.94,275.073C1040.52,275.073 1037.66,276.458 1035.36,279.226C1033.06,281.995 1031.9,285.308 1031.9,289.165L1031.9,314.455L1023.32,314.455L1023.32,268.728Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1093.96,308.109C1098.19,308.109 1101.65,306.585 1104.32,303.536C1107.12,300.488 1108.52,296.506 1108.52,291.591C1108.52,286.801 1107.12,282.85 1104.32,279.739C1101.59,276.629 1098.13,275.073 1093.96,275.073C1089.86,275.073 1086.4,276.629 1083.61,279.739C1080.81,282.85 1079.4,286.801 1079.4,291.591C1079.4,296.444 1080.81,300.395 1083.61,303.443C1086.4,306.554 1089.86,308.109 1093.96,308.109ZM1093.68,336.105C1091.13,336.105 1088.74,335.779 1086.5,335.126C1084.26,334.472 1082.22,333.555 1080.38,332.373C1078.55,331.191 1076.98,329.791 1075.67,328.173C1074.37,326.556 1073.37,324.751 1072.69,322.761L1080.81,319.401C1081.74,322.076 1083.36,324.223 1085.66,325.84C1087.96,327.458 1090.63,328.266 1093.68,328.266C1098.35,328.266 1101.99,326.867 1104.6,324.067C1107.21,321.267 1108.52,317.41 1108.52,312.495L1108.52,308.109L1108.15,308.109C1106.53,310.535 1104.34,312.449 1101.57,313.848C1098.8,315.248 1095.8,315.948 1092.56,315.948C1086.59,315.948 1081.46,313.615 1077.17,308.949C1072.93,304.158 1070.82,298.373 1070.82,291.591C1070.82,284.81 1072.93,279.055 1077.17,274.327C1081.46,269.599 1086.59,267.234 1092.56,267.234C1095.8,267.234 1098.8,267.934 1101.57,269.334C1104.34,270.734 1106.53,272.647 1108.15,275.073L1108.52,275.073L1108.52,268.728L1116.73,268.728L1116.73,312.495C1116.73,319.836 1114.65,325.591 1110.48,329.76C1106.25,333.99 1100.65,336.105 1093.68,336.105Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <rect x="1127.19" y="281.979" width="29.863" height="7.092" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></rect> <path d="M1193.26,258.182L1182.34,288.325L1204.55,288.325L1193.63,258.182L1193.26,258.182ZM1172.91,314.455L1163.39,314.455L1188.59,247.637L1198.3,247.637L1223.49,314.455L1213.98,314.455L1207.54,296.351L1179.45,296.351L1172.91,314.455Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1229.84,268.728L1238.05,268.728L1238.05,275.073L1238.42,275.073C1239.73,272.834 1241.74,270.967 1244.44,269.474C1247.15,267.981 1249.97,267.234 1252.89,267.234C1258.49,267.234 1262.8,268.836 1265.82,272.04C1268.83,275.244 1270.34,279.802 1270.34,285.712L1270.34,314.455L1261.76,314.455L1261.76,286.272C1261.57,278.806 1257.8,275.073 1250.46,275.073C1247.04,275.073 1244.18,276.458 1241.88,279.226C1239.58,281.995 1238.42,285.308 1238.42,289.165L1238.42,314.455L1229.84,314.455L1229.84,268.728Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path> <path d="M1300.48,308.109C1304.71,308.109 1308.17,306.585 1310.84,303.536C1313.64,300.488 1315.04,296.506 1315.04,291.591C1315.04,286.801 1313.64,282.85 1310.84,279.739C1308.11,276.629 1304.65,275.073 1300.48,275.073C1296.38,275.073 1292.92,276.629 1290.12,279.739C1287.33,282.85 1285.92,286.801 1285.92,291.591C1285.92,296.444 1287.33,300.395 1290.12,303.443C1292.92,306.554 1296.38,308.109 1300.48,308.109ZM1300.2,336.105C1297.65,336.105 1295.26,335.779 1293.02,335.126C1290.78,334.472 1288.74,333.555 1286.9,332.373C1285.07,331.191 1283.5,329.791 1282.19,328.173C1280.89,326.556 1279.89,324.751 1279.21,322.761L1287.33,319.401C1288.26,322.076 1289.88,324.223 1292.18,325.84C1294.48,327.458 1297.15,328.266 1300.2,328.266C1304.87,328.266 1308.51,326.867 1311.12,324.067C1313.74,321.267 1315.04,317.41 1315.04,312.495L1315.04,308.109L1314.67,308.109C1313.05,310.535 1310.86,312.449 1308.09,313.848C1305.32,315.248 1302.32,315.948 1299.08,315.948C1293.11,315.948 1287.98,313.615 1283.69,308.949C1279.45,304.158 1277.34,298.373 1277.34,291.591C1277.34,284.81 1279.45,279.055 1283.69,274.327C1287.98,269.599 1293.11,267.234 1299.08,267.234C1302.32,267.234 1305.32,267.934 1308.09,269.334C1310.86,270.734 1313.05,272.647 1314.67,275.073L1315.04,275.073L1315.04,268.728L1323.25,268.728L1323.25,312.495C1323.25,319.836 1321.17,325.591 1317,329.76C1312.77,333.99 1307.17,336.105 1300.2,336.105Z" style="fill:#676c72;fill-rule:nonzero" data-v-6b5b6345></path></g></svg></div> <div class="text-xs md:text-sm text-gray-500 mt-8 md:mt-0 mb-3">
            Designed and Developed by <a href="https://github.com/thepenielcho" target="blank" class="underline">Peniel Cho</a></div></div></footer></div></div></div><script defer src="/_nuxt/static/1668135659/articles/ai_ml-study-ch3/state.js"></script><script src="/_nuxt/4f860e4.js" defer></script><script src="/_nuxt/2251c94.js" defer></script><script src="/_nuxt/05e7f4a.js" defer></script><script src="/_nuxt/f5f1fb1.js" defer></script><script src="/_nuxt/0145610.js" defer></script>
  </body>
</html>
